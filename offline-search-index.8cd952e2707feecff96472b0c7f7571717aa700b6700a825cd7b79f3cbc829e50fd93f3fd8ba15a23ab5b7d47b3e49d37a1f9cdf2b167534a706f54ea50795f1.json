[{"body":" cf-operator cf-operator manages BOSH deployments on Kubernetes\nSynopsis cf-operator manages BOSH deployments on Kubernetes\ncf-operator [flags]  Options  --apply-crd (APPLY_CRD) If true, apply CRDs on start (default true) --bosh-dns-docker-image string (BOSH_DNS_DOCKER_IMAGE) The docker image used for emulating bosh DNS (a CoreDNS image) (default \"coredns/coredns:1.6.3\") -n, --cf-operator-namespace string (CF_OPERATOR_NAMESPACE) The operator namespace, for the webhook service (default \"default\") --cluster-domain string (CLUSTER_DOMAIN) The Kubernetes cluster domain (default \"cluster.local\") --ctx-timeout int (CTX_TIMEOUT) context timeout for each k8s API request in seconds (default 300) -o, --docker-image-org string (DOCKER_IMAGE_ORG) Dockerhub organization that provides the operator docker image (default \"cfcontainerization\") --docker-image-pull-policy string (DOCKER_IMAGE_PULL_POLICY) Image pull policy (default \"IfNotPresent\") -r, --docker-image-repository string (DOCKER_IMAGE_REPOSITORY) Dockerhub repository that provides the operator docker image (default \"cf-operator\") -t, --docker-image-tag string (DOCKER_IMAGE_TAG) Tag of the operator docker image (default \"0.0.1\") -h, --help help for cf-operator -c, --kubeconfig string (KUBECONFIG) Path to a kubeconfig, not required in-cluster -l, --log-level string (LOG_LEVEL) Only print log messages from this level onward (trace,debug,info,warn) (default \"debug\") -i, --logrotate-interval int (LOGROTATE_INTERVAL) Interval between logrotate calls for instance groups in minutes (default 1440) --max-boshdeployment-workers int (MAX_BOSHDEPLOYMENT_WORKERS) Maximum number of workers concurrently running BOSHDeployment controller (default 1) --max-quarks-statefulset-workers int (MAX_QUARKS_STATEFULSET_WORKERS) Maximum number of workers concurrently running QuarksStatefulSet controller (default 1) --meltdown-duration int (MELTDOWN_DURATION) Duration (in seconds) of the meltdown period, in which we postpone further reconciles for the same resource (default 60) --meltdown-requeue-after int (MELTDOWN_REQUEUE_AFTER) Duration (in seconds) for which we delay the requeuing of the reconcile (default 30) --monitored-id string (MONITORED_ID) only monitor namespaces with this id in their namespace label (default \"default\") -w, --operator-webhook-service-host string (CF_OPERATOR_WEBHOOK_SERVICE_HOST) Hostname/IP under which the webhook server can be reached from the cluster -p, --operator-webhook-service-port string (CF_OPERATOR_WEBHOOK_SERVICE_PORT) Port the webhook server listens on (default \"2999\") -x, --operator-webhook-use-service-reference (CF_OPERATOR_WEBHOOK_USE_SERVICE_REFERENCE) If true the webhook service is targeted using a service reference instead of a URL  SEE ALSO  cf-operator util - Calls a utility subcommand cf-operator version - Print the version number  Auto generated by spf13/cobra on 25-Aug-2020 ","excerpt":" cf-operator cf-operator manages BOSH deployments on Kubernetes …","ref":"/docs/commands/cf-operator/cf-operator/","title":"cf-operator"},{"body":" cf-operator util Calls a utility subcommand\nSynopsis Calls a utility subcommand.\nOptions  -h, --help help for util  SEE ALSO  cf-operator - cf-operator manages BOSH deployments on Kubernetes cf-operator util instance-group - Resolves instance group properties of a BOSH manifest cf-operator util tail-logs - Tail logs from a pod cf-operator util template-render - Renders a bosh manifest cf-operator util wait - Wait for required service  Auto generated by spf13/cobra on 25-Aug-2020 ","excerpt":" cf-operator util Calls a utility subcommand\nSynopsis Calls a utility …","ref":"/docs/commands/cf-operator/cf-operator_util/","title":"cf-operator util"},{"body":" cf-operator util instance-group Resolves instance group properties of a BOSH manifest\nSynopsis Resolves instance group properties of a BOSH manifest.\nThis will resolve the properties of an instance group and return a manifest for that instance group. Also calculates and prints the BPM configurations for all BOSH jobs of that instance group.\ncf-operator util instance-group [flags]  Options  -b, --base-dir string (BASE_DIR) a path to the base directory -m, --bosh-manifest-path string (BOSH_MANIFEST_PATH) path to the bosh manifest file -n, --deployment-name string (DEPLOYMENT_NAME) name of the bdpl resource -h, --help help for instance-group --initial-rollout (INITIAL_ROLLOUT) Initial rollout of bosh deployment. (default true) -g, --instance-group-name string (INSTANCE_GROUP_NAME) name of the instance group for data gathering --output-file-path string (OUTPUT_FILE_PATH) Path of the file to which json output is written.  SEE ALSO  cf-operator util - Calls a utility subcommand  Auto generated by spf13/cobra on 25-Aug-2020 ","excerpt":" cf-operator util instance-group Resolves instance group properties of …","ref":"/docs/commands/cf-operator/cf-operator_util_instance-group/","title":"cf-operator util instance-group"},{"body":" cf-operator util tail-logs Tail logs from a pod\nSynopsis Tail logs from a container in the same pod.\nThis will tail all logs under the specified dir. The dir can be set using the “-z” flag, or setting the LOGS_DIR env variable. It will also run logrotate.\ncf-operator util tail-logs [flags]  Options  -h, --help help for tail-logs -i, --logrotate-interval int (LOGROTATE_INTERVAL) interval between logrotates in minutes (default 1440) -z, --logs-dir string (LOGS_DIR) a path from where to tail logs  SEE ALSO  cf-operator util - Calls a utility subcommand  Auto generated by spf13/cobra on 25-Aug-2020 ","excerpt":" cf-operator util tail-logs Tail logs from a pod\nSynopsis Tail logs …","ref":"/docs/commands/cf-operator/cf-operator_util_tail-logs/","title":"cf-operator util tail-logs"},{"body":" cf-operator util template-render Renders a bosh manifest\nSynopsis Renders a bosh manifest.\nThis will render a provided manifest instance-group\ncf-operator util template-render [flags]  Options  --az-index int (AZ_INDEX) az index (default -1) -m, --bosh-manifest-path string (BOSH_MANIFEST_PATH) path to the bosh manifest file -h, --help help for template-render --initial-rollout (INITIAL_ROLLOUT) Initial rollout of bosh deployment. (default true) -g, --instance-group-name string (INSTANCE_GROUP_NAME) name of the instance group for data gathering -j, --jobs-dir string (JOBS_DIR) path to the jobs dir. -d, --output-dir string (OUTPUT_DIR) path to output dir. (default \"/var/vcap/jobs\") --pod-ip string (POD_IP) pod IP --pod-ordinal int (POD_ORDINAL) pod ordinal (default -1) --replicas int (REPLICAS) number of replicas (default -1) --spec-index int (SPEC_INDEX) index of the instance spec (default -1)  SEE ALSO  cf-operator util - Calls a utility subcommand  Auto generated by spf13/cobra on 25-Aug-2020 ","excerpt":" cf-operator util template-render Renders a bosh manifest\nSynopsis …","ref":"/docs/commands/cf-operator/cf-operator_util_template-render/","title":"cf-operator util template-render"},{"body":" cf-operator util variable-interpolation Interpolate variables\nSynopsis Interpolate variables of a manifest:\nThis will interpolate all the variables from a folder and write an interpolated manifest to STDOUT\ncf-operator util variable-interpolation [flags]  Options  -m, --bosh-manifest-path string (BOSH_MANIFEST_PATH) path to the bosh manifest file -h, --help help for variable-interpolation --output-file-path string (OUTPUT_FILE_PATH) Path of the file to which json output is written. -v, --variables-dir string (VARIABLES_DIR) path to the variables dir  SEE ALSO  cf-operator util - Calls a utility subcommand  Auto generated by spf13/cobra on 7-Aug-2020 ","excerpt":" cf-operator util variable-interpolation Interpolate variables …","ref":"/docs/commands/cf-operator/cf-operator_util_variable-interpolation/","title":"cf-operator util variable-interpolation"},{"body":" cf-operator util wait Wait for required service\nSynopsis Wait for required service\ncf-operator util wait [flags]  Options  -h, --help help for wait --interval int interval between checks in seconds (default 1) --timeout int timeout in seconds after the required service must be available (default 1800)  SEE ALSO  cf-operator util - Calls a utility subcommand  Auto generated by spf13/cobra on 25-Aug-2020 ","excerpt":" cf-operator util wait Wait for required service\nSynopsis Wait for …","ref":"/docs/commands/cf-operator/cf-operator_util_wait/","title":"cf-operator util wait"},{"body":" cf-operator version Print the version number\nSynopsis Print the version number\ncf-operator version [flags]  Options  -h, --help help for version  SEE ALSO  cf-operator - cf-operator manages BOSH deployments on Kubernetes  Auto generated by spf13/cobra on 25-Aug-2020 ","excerpt":" cf-operator version Print the version number\nSynopsis Print the …","ref":"/docs/commands/cf-operator/cf-operator_version/","title":"cf-operator version"},{"body":"  Development  Requirements Dependencies Creating a new Resource and Controller Reconcile Results Testing Create-Or-Update pattern Logging and Events Standalone Components Versioning Colourise Logs   Requirements  A working Kubernetes cluster Helm v3 binary Go 1.12.2 and install the tool chain: make tools  Dependencies Run with libraries fetched via go modules:\n1  export GO111MODULE=on   Custom Resource Definitions (CRDs) Kubernetes allows developers to extend the objects its APIs process and store using Custom Resource Definitions (CRDs). We are creating four CRDs (see Controllers):\n BOSHDeployment QuarksJob QuarksSecret QuarksStatefulSet  The CRDs are also defined in code and applied automatically when cf-operator starts. If you are editing CRDs, you should update changes to this YAML files in sync.\nCreating a new Resource and Controller  create a new directory: ./pkg/kube/apis/\u003cgroup_name\u003e/\u003cversion\u003e in that directory, create the following files:  types.go register.go doc.go    You can safely use the implementation from another controller as inspiration. You can also copy the files and modify them.\n The types.go file contains the definition of your resource. This is the file you care about. Make sure to run make generate every time you make a change. You can also check to see what changes would be done by running make verify-gen-kube.\nThe register.go file contains some code that registers your new types. This file looks almost the same for all API resources.\nThe doc.go (deep object copy) is required to make the deepcopy generator work. It’s safe to copy this file from another controller.\n in bin/gen-kube, add your resource to the GROUP_VERSIONS variable (separated by a space \" \"):\n1 2 3  # ... GROUP_VERSIONS=\"boshdeployment:v1alpha1 \u003ccontroller_name\u003e:\u003cversion\u003e\" # ...   regenerate code\n1 2  # int the root of the project make generate   create a directory structure like this for your actual controller code:\n1 2 3 4 5 6 7 8  . +-- pkg +-- kube +-- controllers +-- \u003ccontroller_name\u003e ¦ +-- controller.go ¦ +-- reconciler.go +-- controller.go    controller.go is your controller implementation; this is where you should implement an Add function where register the controller with the Manager, and you watch for changes for resources that you care about. reconciler.go contains the code that takes action and reconciles actual state with desired state.   Simple implementation to get you started below. As always, use the other implementations to get you started.\nController:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  package mycontroller import ( \"go.uber.org/zap\" \"sigs.k8s.io/controller-runtime/pkg/controller\" \"sigs.k8s.io/controller-runtime/pkg/controller/controllerutil\" \"sigs.k8s.io/controller-runtime/pkg/handler\" \"sigs.k8s.io/controller-runtime/pkg/manager\" \"sigs.k8s.io/controller-runtime/pkg/source\" mrcv1 \"code.cloudfoundry.org/quarks-operator/pkg/kube/apis/myresourcecontroller/v1\" ) func Add(log *zap.SugaredLogger, mgr manager.Manager) error { r := NewReconciler(log, mgr, controllerutil.SetControllerReference) // Create a new controller  c, err := controller.New(\"myresource-controller\", mgr, controller.Options{Reconciler: r}) if err != nil { return err } // Watch for changes to primary resource  err = c.Watch(\u0026source.Kind{Type: \u0026mrcv1.MyResource{}}, \u0026handler.EnqueueRequestForObject{}) if err != nil { return err } return nil }   Reconciler:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  package myresource import ( \"go.uber.org/zap\" metav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\" \"k8s.io/apimachinery/pkg/runtime\" \"sigs.k8s.io/controller-runtime/pkg/client\" \"sigs.k8s.io/controller-runtime/pkg/manager\" \"sigs.k8s.io/controller-runtime/pkg/reconcile\" ) type setReferenceFunc func(owner, object metav1.Object, scheme *runtime.Scheme) error func NewReconciler(log *zap.SugaredLogger, mgr manager.Manager, srf setReferenceFunc) reconcile.Reconciler { return \u0026ReconcileMyResource{ log: log, client: mgr.GetClient(), scheme: mgr.GetScheme(), setReference: srf, } } type ReconcileMyResource struct { client client.Client scheme *runtime.Scheme setReference setReferenceFunc log *zap.SugaredLogger } func (r *ReconcileMyResource) Reconcile(request reconcile.Request) (reconcile.Result, error) { r.log.Infof(\"Reconciling MyResource %s\\n\", request.NamespacedName) return reconcile.Result{}, nil }    add the new resource to addToSchemes in pkg/controllers/controller.go. add the new controller to addToManagerFuncs in the same file. create a custom resource definition and add docs to docs/crds.  Reconcile Results 1 2 3 4 5 6 7 8  // RequeueOnError will requeue if reconcile also returns an error RequeueOnError = reconcile.Result{} // Requeue will requeue the request, behaviour is different than returning an error Requeue = reconcile.Result{Requeue: true} // RequeueAfterDefault requeues after the default, unless reconcile also returns an error RequeueAfterDefault = reconcile.Result{RequeueAfter: config.RequeueAfter} // NoRequeue does not requeue, unless reconcile also returns an error NoRequeue = reconcile.Result{Requeue: false}   Testing  create functions in env/machine create functions in env/catalog  Create-Or-Update pattern A pattern that comes up quite often is that an object needs to be updated if it already exists or created if it doesn’t. controller-runtime provides the controller-util package which has a CreateOrUpdate function that can help with that. The object’s desired state must be reconciled with the existing state inside the passed in callback MutateFn - type MutateFn func() error. The MutateFn is called regardless of creating or updating an object.\n1 2 3 4 5 6 7 8 9 10  _, err = controllerutil.CreateOrUpdate(ctx, r.client, someSecret, secretMutateFn(someSecret, someSecret.StringData, someSecret.Labels, someSecret.Annotations)) func secretMutateFn(s *corev1.Secret, secretData map[string]string, labels map[string]string, annotations map[string]string) controllerutil.MutateFn { return func() error { s.Labels = labels s.Annotations = annotations s.StringData = secretData return nil } }    Care must be taken when persisting objects that are already in their final state because they will be overwritten with the existing state if there already is such an object in the system. CreateOrUpdates should not use blindly DeepCopyInto or DeepCopy all the time, but make more precise changes.  Logging and Events We start with a single context and pass that down via controllers into reconcilers. Reconcilers will create a context with timeout from the inherited context and linting will check if the cancel() function of that context is being handled.\nThe ctxlog module provides a context with a named zap logger and an event recorder to the reconcilers. This is how it’s set up for reconcilers:\n1 2 3 4 5 6 7  // after logger is available ctx := ctxlog.NewParentContext(log) // adding named log and event recorder in controllers ctx = ctxlog.NewContextWithRecorder(ctx, \"example-reconciler\", mgr.GetEventRecorderFor(\"example-recorder\")) // adding timeout in reconcilers ctx, cancel := context.WithTimeout(ctx, timeout) defer cancel()   The ctxlog package provides several logging functions. Infof, Errorf, Error and such wrap the corresponding zap log methods.\nThe logging functions are also implemented on struct, to add event generation to the logging:\n1 2 3  ctxlog.WithEvent(instance, \"Reason\").Infof(\"message: %s\", v) err := ctxlog.WithEvent(instance, \"Reason\").Errorf(\"message: %s\", v) err := ctxlog.WithEvent(instance, \"Reason\").Error(\"part\", \"part\", \"part\")   The reason should be camel-case, so switch statements could match it.\nError funcs like WithEvent().Errorf() also return an error, with the same message as the log message and event that were generated.\nCalling WarningEvent just creates a warning event, without logging.\nStandalone Components The cf-operator uses quarks-job as an external component. The quarks-job operator is run in a separate process.\nWhen using jobs that capture output, quarks-job needs to know its docker image, to run the persist-output command in a container.\nReferences in cf-operator References to quarks job:\n as a library, for the API type, via git commit sha in go.mod: ‘b5dc240’ the docker image for integration tests is set via QUARKS_JOB_IMAGE_TAG: ‘v0.0.0-0.gb5dc240’ releases and e2e test use the helm sub chart, build by bin/build-helm, which uses the QUARKS_JOB_HELM_VERSION variable: ‘0.0.0-0.gb5dc240’  Both variables are set in bin/include/dependencies.\nUpdate Dependencies To update a dependency in a project use go get, e.g.:\ngo get -t -u code.cloudfoundry.org/quarks-job@aad515c  Using the git commit sha prevents caching problems, which might occur with branch names.\nLocal Development And go mod ‘replace’ When working locally with multiple repositories it’s helpful to replace github dependencies with local directories. The go mod edit -replace will modify the go.mod file to point to a local dir, e.g. ‘../quarks-job’ instead:\ngo mod edit -replace code.cloudfoundry.org/quarks-utils=../quarks-utils go mod edit -replace code.cloudfoundry.org/quarks-job=../quarks-job  Building Docker Image When Using go mod ‘replace’ The modified libraries are not visible to the container. As a workaround a vendor folder can be used, which is also faster:\nGO111MODULE=on go mod vendor GO111MODULE=off make build-image rm -fr vendor  Use a Local QuarksJob Image in Integration Tests To use a local docker image export QUARKS_JOB_IMAGE_TAG and make sure the image is available to the cluster, e.g. for kind:\nkind load docker-image cfcontainerization/cf-operator:$DOCKER_IMAGE_TAG kind load docker-image cfcontainerization/quarks-job:$QUARKS_JOB_IMAGE_TAG  Use a Local QuarksJob Image in Integration Tests with Kubernetes for Docker Desktop To use a local docker image export QUARKS_JOB_IMAGE_TAG and make sure the image is available to the cluster, e.g. for kind:\ndocker tag \u003ccf-operator-tag\u003e cfcontainerization/cf-operator:$DOCKER_IMAGE_TAG docker tag \u003cquarks-job-tag\u003e cfcontainerization/quarks-job:$QUARKS_JOB_IMAGE_TAG  Merging PRs  In PR reviews, make sure only reviewed branches of dependencies are used. If several PRs across repos belong together, be careful to merge them together and in order, so that the master branches stay compatible if one of the merges fails. Make sure that the cf-operator repo PR has updated value of quarks image tag or version at these places  Dependency File Go mod file   Versioning APIs and types follow the upstream versioning scheme described at: https://kubernetes.io/docs/concepts/overview/kubernetes-api/#api-versioning\nColourise Logs Copy the grc (generic colouriser grcat) config file zap.grc.conf to /usr/share/grc/conf.zap and pipe logs to grcat conf.zap:\n# install the custom log config cp docs/zap.grc.conf /usr/share/grc/conf.zap # running operator kubectl get pods -A -l name=cf-operator --no-headers=true | tail -1 | read namespace name _ kubectl logs -f -n \"$namespace\" \"$name\" | grcat conf.zap # integration tests example grcat conf.zap \u003c /tmp/cf-operator-tests.log  ","excerpt":"  Development  Requirements Dependencies Creating a new Resource and …","ref":"/docs/development/development/","title":"Development Guidelines"},{"body":" The quarks-operator can be installed via helm. You can use our helm repository.\nSee the releases page for up-to-date instructions on how to install the operator.\nFor more information about the quarks-operator helm chart and how to configure it, please refer to the helm repository README.md. A short summary of the installation steps is presented below.\nPrerequisites  Kubernetes cluster helm kubectl  Installation Add the quarks repository to helm if you haven’t already:\n1  helm repo add quarks https://cloudfoundry-incubator.github.io/quarks-helm/   The simplest way to install the operator, is by using the default values:\n1  helm install cf-operator quarks/cf-operator --namespace cf-operator   The operator will watch for BOSH deployments in separate namespaces, not the one it has been deployed to. By default, it creates a namespace staging and starts watching it.\nA complete list of the chart settings is available here.\nMultiple namespaces The quarks-operator watches namespaces labeled with quarks.cloudfoundry.org/monitored=ID. The ID has to be specified with helm settings during install (--set \"global.monitoredID=ID\"). The helm value setting global.singleNamespace.name= allows to automatically create a namespace which is being watched by the quarks-operator.\nFor example, to watch to a different namespace with a specific ID:\n1 2 3 4 5  helm install relname1 quarks/cf-operator \\  --namespace namespace1 --set \"global.singleNamespace.name=staging1\" \\  --set \"global.monitoredID=id1\" \\  --set \"quarks-job.persistOutputClusterRole.name=clusterrole1\"   Using multiple namespaces with one operator The cluster role can be reused between namespaces. The service account (and role binding) should be different for each namespace.\n1 2  helm install relname1 quarks/cf-operator \\  --set \"global.singleNamespace.create=false\"   Manually create before running helm install, for each namespace:\n a namespace “staging1” with the following labels (note: “cfo” and “qjob-persist-output” are the defaults from values.yaml):\n quarks.cloudfoundry.org/monitored: \"cfo\" quarks.cloudfoundry.org/qjob-service-account: qjob-persist-output  a service account named “qjob-persist-output”\n a role binding from the existing cluster role “qjob-persist-output” to “qjob-persist-output” service account in namespace “staging1”\n  For more options look at the README for the chart\n1  helm show readme quarks/cf-operator   What next? With a running quarks-operator pod, you can try one of the files (see boshdeployment-with-custom-variable.yaml ), as follows (if you installed it with default values):\n1  kubectl -n staging apply -f https://raw.githubusercontent.com/cloudfoundry-incubator/quarks-operator/master/docs/examples/bosh-deployment/boshdeployment-with-custom-variable.yaml   The above will spawn two pods in your cf-operator namespace (which needs to be created upfront), running the BOSH nats release.\nYou can access the quarks-operator logs by following the operator pod’s output:\n1  kubectl logs -f -n cf-operator cf-operator   Or look at the k8s event log:\n1  kubectl get events -n cf-operator --watch   Modifying the deployment The main input to the operator is the BOSH deployment custom resource and the according manifest config map or secret. Changes to the Spec or Data fields of either of those will trigger the operator to recalculate the desired state and apply the required changes from the current state.\n Note:\nEach creation or update can trigger the creation of multiple pods with the dm- or ig- prefix. Those are warm up jobs, which are preparing manifests and eventually configure the pods your BOSH releases will be running on. When dm- and ig- pods are completed, the pods are ready to start up. See also Bosh deployment status.\n Besides that there are more things the user can change which will trigger an update of the deployment:\n ops files can be added or removed from the BOSH deployment. Existing ops file config maps and secrets can be modified generated secrets for explicit variables can be modified secrets for implicit variables have to be created by the user beforehand anyway, but can also be changed after the initial deployment  ","excerpt":" The quarks-operator can be installed via helm. You can use our helm …","ref":"/docs/core-tasks/install/","title":"Install"},{"body":" quarks-job quarks-job starts the operator\nSynopsis quarks-job starts the operator\nquarks-job [flags]  Options  --apply-crd (APPLY_CRD) If true, apply CRDs on start (default true) --ctx-timeout int (CTX_TIMEOUT) context timeout for each k8s API request in seconds (default 300) -o, --docker-image-org string (DOCKER_IMAGE_ORG) Dockerhub organization that provides the operator docker image (default \"cfcontainerization\") --docker-image-pull-policy string (DOCKER_IMAGE_PULL_POLICY) Image pull policy (default \"IfNotPresent\") -r, --docker-image-repository string (DOCKER_IMAGE_REPOSITORY) Dockerhub repository that provides the operator docker image (default \"quarks-job\") -t, --docker-image-tag string (DOCKER_IMAGE_TAG) Tag of the operator docker image (default \"0.0.1\") -h, --help help for quarks-job -c, --kubeconfig string (KUBECONFIG) Path to a kubeconfig, not required in-cluster -l, --log-level string (LOG_LEVEL) Only print log messages from this level onward (trace,debug,info,warn) (default \"debug\") --max-workers int (MAX_WORKERS) Maximum number of workers concurrently running the controller (default 1) --meltdown-duration int (MELTDOWN_DURATION) Duration (in seconds) of the meltdown period, in which we postpone further reconciles for the same resource (default 60) --meltdown-requeue-after int (MELTDOWN_REQUEUE_AFTER) Duration (in seconds) for which we delay the requeuing of the reconcile (default 30) --monitored-id string (MONITORED_ID) only monitor namespaces with this id in their namespace label (default \"default\")  SEE ALSO  quarks-job persist-output - Persist a file into a kube secret quarks-job version - Print the version number  Auto generated by spf13/cobra on 25-Aug-2020 ","excerpt":" quarks-job quarks-job starts the operator\nSynopsis quarks-job starts …","ref":"/docs/commands/quarks-job/quarks-job/","title":"quarks-job"},{"body":" quarks-job persist-output Persist a file into a kube secret\nSynopsis Persists a log file created by containers in a pod of quarksJob\ninto a versioned secret or kube native secret using flags specified to this command.\nquarks-job persist-output [flags]  Options  -h, --help help for persist-output --namespace string (NAMESPACE) namespace where persist output will run (default \"default\")  Options inherited from parent commands  --apply-crd (APPLY_CRD) If true, apply CRDs on start (default true) --ctx-timeout int (CTX_TIMEOUT) context timeout for each k8s API request in seconds (default 300) -o, --docker-image-org string (DOCKER_IMAGE_ORG) Dockerhub organization that provides the operator docker image (default \"cfcontainerization\") --docker-image-pull-policy string (DOCKER_IMAGE_PULL_POLICY) Image pull policy (default \"IfNotPresent\") -r, --docker-image-repository string (DOCKER_IMAGE_REPOSITORY) Dockerhub repository that provides the operator docker image (default \"quarks-job\") -t, --docker-image-tag string (DOCKER_IMAGE_TAG) Tag of the operator docker image (default \"0.0.1\") -c, --kubeconfig string (KUBECONFIG) Path to a kubeconfig, not required in-cluster -l, --log-level string (LOG_LEVEL) Only print log messages from this level onward (trace,debug,info,warn) (default \"debug\") --max-workers int (MAX_WORKERS) Maximum number of workers concurrently running the controller (default 1) --meltdown-duration int (MELTDOWN_DURATION) Duration (in seconds) of the meltdown period, in which we postpone further reconciles for the same resource (default 60) --meltdown-requeue-after int (MELTDOWN_REQUEUE_AFTER) Duration (in seconds) for which we delay the requeuing of the reconcile (default 30) --monitored-id string (MONITORED_ID) only monitor namespaces with this id in their namespace label (default \"default\")  SEE ALSO  quarks-job - quarks-job starts the operator  Auto generated by spf13/cobra on 25-Aug-2020 ","excerpt":" quarks-job persist-output Persist a file into a kube secret\nSynopsis …","ref":"/docs/commands/quarks-job/quarks-job_persist-output/","title":"quarks-job persist-output"},{"body":" quarks-job version Print the version number\nSynopsis Print the version number\nquarks-job version [flags]  Options  -h, --help help for version  Options inherited from parent commands  --apply-crd (APPLY_CRD) If true, apply CRDs on start (default true) --ctx-timeout int (CTX_TIMEOUT) context timeout for each k8s API request in seconds (default 300) -o, --docker-image-org string (DOCKER_IMAGE_ORG) Dockerhub organization that provides the operator docker image (default \"cfcontainerization\") --docker-image-pull-policy string (DOCKER_IMAGE_PULL_POLICY) Image pull policy (default \"IfNotPresent\") -r, --docker-image-repository string (DOCKER_IMAGE_REPOSITORY) Dockerhub repository that provides the operator docker image (default \"quarks-job\") -t, --docker-image-tag string (DOCKER_IMAGE_TAG) Tag of the operator docker image (default \"0.0.1\") -c, --kubeconfig string (KUBECONFIG) Path to a kubeconfig, not required in-cluster -l, --log-level string (LOG_LEVEL) Only print log messages from this level onward (trace,debug,info,warn) (default \"debug\") --max-workers int (MAX_WORKERS) Maximum number of workers concurrently running the controller (default 1) --meltdown-duration int (MELTDOWN_DURATION) Duration (in seconds) of the meltdown period, in which we postpone further reconciles for the same resource (default 60) --meltdown-requeue-after int (MELTDOWN_REQUEUE_AFTER) Duration (in seconds) for which we delay the requeuing of the reconcile (default 30) --monitored-id string (MONITORED_ID) only monitor namespaces with this id in their namespace label (default \"default\")  SEE ALSO  quarks-job - quarks-job starts the operator  Auto generated by spf13/cobra on 25-Aug-2020 ","excerpt":" quarks-job version Print the version number\nSynopsis Print the …","ref":"/docs/commands/quarks-job/quarks-job_version/","title":"quarks-job version"},{"body":" quarks-secret quarks-secret starts the operator\nSynopsis quarks-secret starts the operator\nquarks-secret [flags]  Options  --apply-crd (APPLY_CRD) If true, apply CRDs on start (default true) --ctx-timeout int (CTX_TIMEOUT) context timeout for each k8s API request in seconds (default 300) -h, --help help for quarks-secret -c, --kubeconfig string (KUBECONFIG) Path to a kubeconfig, not required in-cluster -l, --log-level string (LOG_LEVEL) Only print log messages from this level onward (trace,debug,info,warn) (default \"debug\") --max-workers int (MAX_WORKERS) Maximum number of workers concurrently running the controller (default 1) --meltdown-duration int (MELTDOWN_DURATION) Duration (in seconds) of the meltdown period, in which we postpone further reconciles for the same resource (default 60) --meltdown-requeue-after int (MELTDOWN_REQUEUE_AFTER) Duration (in seconds) for which we delay the requeuing of the reconcile (default 30) --monitored-id string (MONITORED_ID) only monitor namespaces with this id in their namespace label (default \"default\")  SEE ALSO  quarks-secret version - Print the version number  Auto generated by spf13/cobra on 25-Aug-2020 ","excerpt":" quarks-secret quarks-secret starts the operator\nSynopsis …","ref":"/docs/commands/quarks-secret/quarks-secret/","title":"quarks-secret"},{"body":" quarks-secret version Print the version number\nSynopsis Print the version number\nquarks-secret version [flags]  Options  -h, --help help for version  Options inherited from parent commands  --apply-crd (APPLY_CRD) If true, apply CRDs on start (default true) --ctx-timeout int (CTX_TIMEOUT) context timeout for each k8s API request in seconds (default 300) -c, --kubeconfig string (KUBECONFIG) Path to a kubeconfig, not required in-cluster -l, --log-level string (LOG_LEVEL) Only print log messages from this level onward (trace,debug,info,warn) (default \"debug\") --max-workers int (MAX_WORKERS) Maximum number of workers concurrently running the controller (default 1) --meltdown-duration int (MELTDOWN_DURATION) Duration (in seconds) of the meltdown period, in which we postpone further reconciles for the same resource (default 60) --meltdown-requeue-after int (MELTDOWN_REQUEUE_AFTER) Duration (in seconds) for which we delay the requeuing of the reconcile (default 30) --monitored-id string (MONITORED_ID) only monitor namespaces with this id in their namespace label (default \"default\")  SEE ALSO  quarks-secret - quarks-secret starts the operator  Auto generated by spf13/cobra on 25-Aug-2020 ","excerpt":" quarks-secret version Print the version number\nSynopsis Print the …","ref":"/docs/commands/quarks-secret/quarks-secret_version/","title":"quarks-secret version"},{"body":" The following steps layout the process of building quarks-operator (formerly cf-operator) from source and how to install it in your Kubernetes cluster.\nNote The Quarks Operator was previously known as cf-operator. We are renaming the cf-operator project into quarks-operator. Docker images and other sections might not be migrated yet, we are sorry for the confusion.  Build it from source Follow this steps to build a proper docker image and generate a deployable helm chart:\n Checkout the latest stable release / or run it from develop branch\n1  git checkout v0.3.0   Build the cf-operator binary, this will be embedded later on the docker image\n1  bin/build   Build the docker image\nWhen running in minikube, please run: eval $(minikube docker-env), to build the image directly on minikube docker.\n1  bin/build-image   Note: This will automatically generate a docker image tag based on your current commit, tag and SHA.\n Generated helm charts with a proper docker image tag, org and repository\n1  bin/build-helm   Note: This will generate a new directory under the base dir, named helm/\n Install the helm chart(apply Kubernetes Custom Resources)\n1  helm install cf-operator-test helm/cf-operator   Note: The cf-operator will be available under the namespace set in the context, usually default, running as a pod.\n  Notes Local Development with Minikube and Havener Make sure you have havener install.\n1  havener deploy --config dev-env-havener.yaml  ","excerpt":" The following steps layout the process of building quarks-operator …","ref":"/docs/core-tasks/building/","title":"Build"},{"body":"  Testing  Tests description Unit Integration End-to-End Running tests in minikube in KinD Makefile General Targets Build Targets Test Targets Generate Targets CI   Tests description Based on upstreams documentation https://github.com/thtanaka/kubernetes/blob/master/docs/devel/testing.md we use three levels of testing: unit, integration and e2e.\nBefore starting, run make tools to install the required dependencies.\nRunning make test executes all the test suites.\nWe use ginkgo for testing. Every package needs a suite_test.go for setup. It can be generated by running ginkgo bootstrap in the sub folder. Rename the generated file afterwards, to stay consistent. There is also ginkgo generate to create skeleton test files.\nUnit While unit testing we:\n test classes in isolation pass all dependencies to the constructor, so we can inject fakes for testing use counterfeiter and gomock/mockgen to generate and update fakes and mocks don’t test private methods, tests are in a separate _test package try not to nest ginkgo contexts too deep and keep tests DRY by extracting useful helpers assert incoming messages produce the expected state assert outgoing commands happened, like a file gets written assert all handled error cases are triggered can ignore outgoing queries, which only change internal state  Setup Ruby Ruby gem for template rendering\n1  gem install bosh-template   Integration Integration tests formulate expectations on the interactions of several components. They require access to a Kubernetes, preferably minikube.\nIntegration tests start our operator directly, bypassing the command line. They do require the operator docker image and the bosh-template Ruby gem.\nThe environment package provides helpers to start the operator, get the kubeconfig and use the clients to create objects. In testing the catalog defines test objects.\nIntegration tests use a special logger, which does not log to stdout and whose messages can be accessed as a an array by calling env.AllLogMessages().\nWhen using bin/test-integration the integration tests are run in parallel. Each Ginkgo test node has a separate namespace, log file and webhook server port and certificate.\nThe node index starts at 1 and is used as following to generate names:\n1 2 3  namespace: $TEST_NAMESPACE + \u003cnode_index\u003e webhook port: $CF_OPERATOR_WEBHOOK_SERVICE_PORT + \u003cnode_index\u003e log file: $CF_OPERATOR_TESTING_TMP/cf-operator-tests-\u003cnode_index\u003e.log   Integration tests use the TEST_NAMESPACE environment variable as a base to calculate the namespace name. Test namespaces are deleted automatically once the tests are completed.\nCF_OPERATOR_TESTING_TMP can be used to set a tmp directory for storing logs and other files generated during testing. If this variable is not set /tmp will be used instead.\nThe tests will create some NodePort services; normally the test can detect an IP address automatically. CF_OPERATOR_NODE_IP can set to the node IP of any arbitrary node to override this (e.g. for OpenStack Kubernetes clusters).\nGenerated files will be cleand up after the test run unless SKIP_CF_OPERATOR_TESTING_TMP_CLEANUP is set to true.\nWebhook Configuration Quarks StatefulSet requires a k8s webhook to mutate the volumes of a pod. Kubernetes will call back to the operator for certain requests and use the modified pod manifest, which is returned. CF-Operator also uses a validating webhook to validate the BOSH deployment spec and the creation of reference resources specified in the spec. Secret validation admission webhook restricts the user from updating a versioned secret.\nThe cf-operator integration tests use CF_OPERATOR_WEBHOOK_SERVICE_PORT as a base value to calculate the port number to listen to on CF_OPERATOR_WEBHOOK_SERVICE_HOST.\nThe tests use a mutatingwebhookconfiguration and a validatingwebhookconfiguration to configure Kubernetes to connect to this address. The address needs to be reachable from the cluster.\nThe configuration only applies to a single namespace, by using a selector. It contains the URL of the webhooks, build from CF_OPERATOR_WEBHOOK_SERVICE_HOST and the calculated port. It also contains SSL certificates and CA, which are necessary to connect to the webhook.\nThe certificates and keys are written to disk, so the webhook server can use them. They are also cached in a k8s secret for production, but that is not being used in integration tests, since they delete the test namespaces.\nTests suites should clean up their, namespace dependant, webhook configuration automatically.\nEnd-to-End The e2e tests are meant to test acceptance scenarios. They are written from an end user perspective. They are split into two types, ‘cli’ and ‘kube’.\nThe e2e CLI test exercise different command line options and commands which don’t need a running Kubernetes, like template rendering. The CLI tests build the operator binary themselves.\nThe second type of e2e tests use helm to install the CF operator into the k8s cluster and use the files from docs/examples for testing.\nRunning tests In minikube The following steps are necessary to have a proper environment setup, where all types of tests can be executed:\n Start minikube\n1  minikube start --kubernetes-version v1.15.5   Switch to minikube docker daemon\n1  eval $(minikube docker-env)   Note: Template rendering for BOSH jobs is done at deployment time by the operator binary. Therefore the operator docker image needs to be made available to Kubernetes cluster.\n Export the CF_OPERATOR_WEBHOOK_SERVICE_HOST env variable\n1  export CF_OPERATOR_WEBHOOK_SERVICE_HOST=$(ip -4 a s dev $(ip r l 0/0 | cut -f5 -d' ') | grep -oP 'inet \\K\\S+(?=/)')   Note: On Mac, use export CF_OPERATOR_WEBHOOK_SERVICE_HOST=$(ip a s $(ip r g 0/0 | cut -f5 -d' ') | grep -oE 'inet [^ /]+' | cut -f2 -d' '), because grep cannot handle perl regexs. Note: You can also find the correct IP, by running ip addr. The IP address under vboxnet1 is the IP that you need.\n Export the OPERATOR_TEST_STORAGE_CLASS env variable\n1  export OPERATOR_TEST_STORAGE_CLASS=standard   Note: Require for the PVC test creation, in minikube.\n Ensure GO111MODULE is set\n1  export GO111MODULE=on   Note: When you have a vendor folder (either from the submodule or manually created) settings this to off speeds up the build-image target.\n Build the cf-operator binary\n1  bin/build   Build the cf-operator docker image\n1  bin/build-image    Note: Consider setting DOCKER_IMAGE_TAG to a fixed variable. This will avoid rebuilding the docker image everytime, when doing changes in files not related to the cf-operator binary.\nNote: When not running in CI, nothing ensures a proper cleanup of resources after the deletion of the cf-operator in the environment. You can make sure to manually verify that none old resources will interfere with a future installation, by:\n1 2  # Deleting old mutating webhooks configurations kubectl get mutatingwebhookconfiguration -oname | xargs -n 1 kubectl delete   In KinD The following steps are necessary to have a proper environment setup, where all types of tests can be executed:\n Install KinD  Follow the instructions from https://github.com/kubernetes-sigs/kind/\n Start cluster\n1  kind create cluster --image kindest/node:v1.15.6   Export the CF_OPERATOR_WEBHOOK_SERVICE_HOST env variable. Use the IP of the docker bridge or your public IP. Firewall rules may interfere.\n1  export CF_OPERATOR_WEBHOOK_SERVICE_HOST=$(ip -4 a s dev $(ip r l 0/0 | cut -f5 -d' ') | grep -oP 'inet \\K\\S+(?=/)')    Note: On Mac, use export CF_OPERATOR_WEBHOOK_SERVICE_HOST=$(ip a s $(ip r g 0/0 | cut -f5 -d' ') | grep -oE 'inet [^ /]+' | cut -f2 -d' '), because grep cannot handle perl regexs.\n Export the OPERATOR_TEST_STORAGE_CLASS env variable\n1  export OPERATOR_TEST_STORAGE_CLASS=standard   Note: Required for the PVC tests.\n Build the cf-operator docker image\nFirst set the version to something static, not dependant on git:\n1  export DOCKER_IMAGE_TAG=${DOCKER_IMAGE_TAG:-dev}  1  bin/build-image   Or if you have local changes and use go mod edit --replace, follow instructions from development.\n Load image into KinD\nkind load docker-image cfcontainerization/cf-operator:$DOCKER_IMAGE_TAG  Set QuarksJob dependency. Choose a tag from docker.io.\nexport QUARKS_JOB_IMAGE_TAG=${QUARKS_JOB_IMAGE_TAG:-dev}  If using a locally built quarks-job image, load it via\nkind load docker-image cfcontainerization/quarks-job:$QUARKS_JOB_IMAGE_TAG\n(see development).\nMakefile The following are the make targets available and their actions. When building and running the targets manually on the quarks-operator codebase, please set PROJECT=quarks-operator.\nThe common scripts between the quarks-operator components are in the quarks-utils project. To download them, make sure to run bin/tools-shared or make tools before running any other script/target.\nGeneral Targets    Name Action     all install dependencies, run tests and builds cf-operator binary.   up starts the operator using the binary created by build make target.   vet runs the code analyzing tool vet to identify problems in the source code.   lint runs go lintto identify style mistakes.   tools installs go dependencies required to cf-operator.   check-scripts runs shellcheck to identify syntax, semmantic and subtle caveats in shell scripts.    Build Targets    Name Action     build builds the cf-operator binary.   build-image builds the cf-operator docker image.   build-helm builds the cf-operator helm tar file.    Test Targets    Name Action     test runs unit,integration and e2e tests.   test-unit runs unit tests only.   test-integration runs integration tests only.   test-cli-e2e runs end to end tests for CLI.   test-helm-e2e runs end to end tests on k8s using helm install.   test-integration-storage runs integration storage tests.   test-helm-e2e-storage runs e2e storage tests.    Generate Targets    Name Action     generate runs gen-kube and gen-fakes.   gen-kube generates kube client,informers, lister code.   gen-fakes generates fake objects for unit testing.   gen-command-docs generates docs for all commands.   verify-gen-kube informs if you need to run gen-kube make target.    CI Our Concourse pipeline definitions are kept in the cf-operator-ci repo.\n  ","excerpt":"  Testing  Tests description Unit Integration End-to-End Running tests …","ref":"/docs/development/testing/","title":"Testing"},{"body":" We’re releasing based on tags, which contain our version number. The format is ‘v0.0.0’. The release title will be set to this version.\nThe CI pipeline has a ‘release’ job, which will update the release on Github. That job triggers itself, when a draft release is created.\nCreate new release pipeline We release from release-branches. Each maintained release has a separate pipeline in Concourse. To create a new pipeline run this in the CI repository:\n1 2  cd pipelines/cf-operator-release ./configure.sh CFO v0.4.x v0.4   Where CFO is your concourse target and v0.4.x is the name of the branch. The last argument, v0.4 is used to filter Github tags, which belong to the release.\nThis allows a separate Github branch and Concourse pipeline for each major version. Within those pipelines, releases can be built from minor versions.\nCreate a new release After completion, the pipeline will create several artifacts:\n helm chart on S3 helm chart in our repo at https://cloudfoundry-incubator.github.io/quarks-helm/ cf-operator binary on S3 docker image of the operator on dockerhub  Running the ‘release’ job will take the latest artificats, which passed through the pipeline and add them to the Github release:\n to the body as Github assets for downloading  The version numbers (v0.0.0-\u003cnumber-of-commits\u003e.\u003ccommit-SHA\u003e) of these assets are taken from the info on S3. They have to match the Github tag, else the release job will fail. The assets will be copied into a ‘release’ folder on S3.\nThe docker image is only referenced from the helm chart and not mentioned in the release, though.\nChecklist Major Release  Create version branch Create a new release pipeline for that branch Unpause pipeline Continue with “Minor Bump”  Minor Bump  Tag commit with new version Push commit Wait for commit to pass release pipeline, ‘publish’ needs to create the binary and helm chart, before the ‘release’ job can run Create a draft Github release for that tag, ‘release’ job triggers Wait for ‘release’ job to finish on Concourse Edit the draft release on Github and publish it  Try not to push to the pipeline again, until step 4 is completed. The ‘release’ job will always take the most recent artifacts from S3. Maybe pause the ‘publish’ job manually to avoid accidental updates.\n","excerpt":" We’re releasing based on tags, which contain our version number. The …","ref":"/docs/development/releasing/","title":"Releasing"},{"body":" High-level Direction  releases are defined in the usual way (a releases block), but the information given is used to build a reference for a docker image each instance group is transformed to an Quarks StatefulSet or an QuarksJob each BOSH Job corresponds to one or more containers in the Pod template defined in the Quarks StatefulSet or the QuarksJob; there’s one container for each process defined in the BPM information of each BOSH Job “explicit” variables are generated using Quarks Secret for rendering of BOSH Job Templates, please read this document we have a concept of Desired Manifests all communication happens through Kubernetes Services, which have deterministic DNS Addresses; you can read more about these here  Open Questions  How do we rename things going from one version to the next?  Missing Features  Canary support in QuarksStatefulSets Missing support for the allow_executions flag in bpm configs  Deployment Lifecycle Please read the documentation for the BOSHDeployment controller.\nExample Deployment Manifest Conversion Details 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341  ---# The name of the deployment. Replace the name with the name of the BOSHDeployment resource# It's used to namespace resources created for this deployment.# Based on docs [1], names should be less than 253 characters. We should limit this to# characters in the operator, to make sure that with any suffix, we won't go beyond the limit.name:\"foo\"# Not used by the cf-operator.# A warning is printed in the logs if this is present.director_uuid:\"bar\"# A hash of director features. We could use this to control operator features as well.features:# Enable variables to be regenerated by the config server (e.g. CredHub) when the variable options change. Default false.# In the cf-operator, if an QuarksSecret is changed, (e.g. a new domain is added to a cert),# the value will be automatically updated.# The operator won't be able to control this behavior.# A warning is printed in the logs if this is present.converge_variables:true# Randomizes AZs for left over instances that cannot be distributed equally between AZs.# Not currently used. It's likely that we'll be able to support this.randomize_az_placement:false# Enables or disables returning of DNS addresses in links.# In Kubernetes we always use DNS addresses.# An error should be returned if this value is set to false.use_dns_addresses:true# A list of all releases used in this deployment.# Required.# Each release's image reference is constructed from this information like this:# \u003curl\u003e/\u003cname\u003e:\u003cstemcell.os\u003e-\u003cstemcell.version\u003e-\u003cversion\u003ereleases:# Name of a release used in the deployment.name:\"capi-release\"# The version of the release to be used.# \"latest\" is not supported by the cf-operator. An error is thrown if \"latest\" is used.version:\"1.0\"# Required for the operator. Link to the registry and organization containing the image.url:\"docker.io/cloudfoundry\"# Not used by the cf-operator.# Integrity of the image itself is handled by whatever# container runtime and the image registry.sha1:\"332ac15609b220a3fdf5efad0e0aa069d8235788\"# Required by the operatorstemcell:# OS of the stemcell used by the release. Used to construct the image name.os:\"opensuse\"# Version of the OS of the stemcell used by the release.version:\"42.3\"# Only used by the cf-operator.# A secret is created with the credentials [2], used by the pods# that reference this release.credentials:username:\"foo\"password:\"secret\"# Not used by the cf-operator.# A warning is logged if this is setstemcells:[]# Specifies how updates are handled# The cf-operator uses some of these settings.update:# The number of pods to deploy in the new version of an QuarksStatefulSet# Once canaries are running, deployment can continue.# TODO: Support for canaries needs implementation in QuarksStatefulSet.canaries:2# Time to wait for canary pods to be ready in a new version of an QuarksStatefulSetcanary_watch_time:100# The maximum number of non-canary instances to update in parallel for an QuarksStatefulSet.# TODO: Support for this needs to be implemented in the controller.max_in_flight:2# TODO: is there a need for this in QuarksStatefulSet (in a readiness Probe?)update_watch_time:0# Not used in cf-operator.# All instance groups are deployed at the same time.# If set to true, a warning is logged.serial:false# Not used in cf-operator.# If set, a warning is logged.vm_strategy:\"\"# Each instance group is converted into an QuarksStatefulSetinstance_groups:# Used to name the QuarksStatefulSet or QuarksJob-name:\"api-az1\"# Support for AZs is implemented in the QuarksStatefulSetazs:[\"az1\"]# Number of replicas for the StatefulSets in an QuarksStatefulSet# If this instance group defines an QuarksJob, this value must be 1. An error is thrown otherwiseinstances:3# Each job results in a rendered bpm.yml file.# BPM information is required - the deployment fails if it's missing.# Each job has one or more processes (defined in bpm.yml), and each corresponds to a container of a pod in a StatefulSet or Jobjobs:# It's used to name the container-name:\"cloud_controller_ng\"# The name of a release that must exist in the releases block.# If it doesn't exist in the releases block, an error is thrown.# The docker image used for the container is resolved using this release name.release:\"capi-release\"# Used by the cf-operator to calculate links before rendering templates.# All resources in the cf-operator are deterministic (IP addresses are not used),# So they can be calculated before template rendering occurs.consumes:{}# Same as the consumes block above.provides:{}# Defines all properties, used to render job templates.# Job templates are rendered as Secrets, and then mounted into pod containers.# If a property is changed, the operator runs rendering in an QuarksJob, and the# template's secret is (re)generated.# All properties are input to this QuarksJob that does rendering.# Some properties can reference variables, which can be generated. The cf-operator# collects values for all properties before starting the rendering process.properties:domain:\"mycf.com\"admin_password:\"((adminpass))\"# Extra information specific to the cf-operatorquarks:run:# Hints for pod replica countscaling:min:1max:3ha:2# Extra capabilities required by the containers of this jobcapabilities:[]# Memory used by each container. Overrides info from vm_resources.memory:128# Number of vCPUs used by each container. Overrides info from vm_resources.virtual-cpus:2# Healthcheck information for the containers in this job.healthcheck:some_process_name:readiness:exec:command:-\"curl --silent --fail --head http://${HOSTNAME}:8080/health\"# List of ports to be opened up for this job.ports:-name:\"health-port\"protocol:\"TCP\"internal:8080# Not used by the cf-operator.# A warning is logged if this is set.vm_type:\"\"# Not used by the cf-operator.# A warning is logged if this is set.vm_extensions:[]# Used by the cf-operator to limit the resources used by a container in a podvm_resources:# Number of vCPUs used by a containercpu:4# Memory used by a containerram:1024# Used for PVC sizes if `ephemeralAsPVC` is set to trueephemeral_disk_size:4096# Not used by the cf-operator.# A warning is logged if this is set.stemcell:\"\"# Size of the volume attached to a pod container.persistent_disk:4096# This must be the name of a StorageClass used by the cf-operator to create volumes.persistent_disk_type:\"default\"# Not used by the cf-operator.# A warning is logged if this key is set.networks:# Not used by the cf-operator-name:\"foo\"# Not used by the cf-operatorstatic_ips:[]# Not used by the cf-operatordefault:[]# Specific update settings for this instance group. Use this to override global job update settings on a per-instance-group basis.update:{}# TODO: understand how instance group renames can occur in an QuarksStatefulSet or QuarksJobmigrated_from:-cloud_controller# This is the key that controls how an instance group is treated by the cf-operator.# If lifecycle is \"service\", an QuarksStatefulSet is created for the instance group.# Otherwise, if it's \"errand\", an QuarksJob is created. As with normal BOSH, errands have a# manual trigger, so QuarksJobs have to support this (manual triggers).# In Kubernetes we also need errands that can run on a trigger. These are not supported by BOSH.# The lifecycle for such an QuarksJob is \"auto-errand\".# Manual triggers are supported by QuarksJobslifecycle:\"service\"# Deprecated - the cf-operator does not support this key.# An error is thrown if this is set.properties:{}# Usually used for BOSH Agent configuration.# We can use this hash to control how the operator generates resources, however# none of the settings used by the Agent are supported by the operator.env:# Not used by the cf-operator.# A warning is logged if this is set.persistent_disk_fs:\"ext4\"# Not used by the cf-operator.# A warning is logged if this is set.persistent_disk_mount_options:[]# Not used by the cf-operator.# A warning is logged if this is set.bosh[Hash,optional]:# Not used by the cf-operator.# A warning is logged if this is set.password:\"foo\"# Not used by the cf-operator.# A warning is logged if this is set.keep_root_password:vcap# Not used by the cf-operator.# A warning is logged if this is set.remove_dev_tools:false# Not used by the cf-operator.# A warning is logged if this is set.remove_static_libraries:false.# Not used by the cf-operator.# A warning is logged if this is set.swap_size:100# Not used by the cf-operator.# A warning is logged if this is set.ipv6:# Not used by the cf-operator.# A warning is logged if this is set.enable:false# Not used by the cf-operator.# A warning is logged if this is set.job_dir:# Not used by the cf-operator.# A warning is logged if this is set.tmpfs:false# Not used by the cf-operator.# A warning is logged if this is set.tmpfs_size:\"0m\"agent:# Not used by the cf-operator.# A warning is logged if this is set.tmpfs:false# Used by the cf-operator to set kubernetes-specific information# for the resources representing this instance group.settings:# Affinity information for this instance group's pod.# These definitions are merged directly into the pod's definition.# The structure is the same as the one used by Kube [3].affinity:{}# Labels to add to the resources representing the instance grouplabels:{}# Annotations to add to the resources representing the instance groupannotations:{}# Ops files that are applied on top of instance group properties yaml or BPM data yamlpreRenderOps:bpm:-type:replacepath:/foovalue:barinstanceGroup:-type:replacepath:/foovalue:bar# disable_log_sidecar is an option to disable log sidecardisable_log_sidecar:false# serviceAccountName is the name of the ServiceAccount to use to run this pod.serviceAccountName:kubecf# automountServiceAccountToken indicates whether a service account token should be automatically mountedautomountServiceAccountToken:false# ImagePullSecrets is an optional list of references to secrets to use for pulling any of the images.# This field in PodSpec can be automated by setting the imagePullSecrets in a serviceAccount.imagePullSecrets:{}# Tolerations and taints are a concept defined in kubernetes to repel pods from nodes. [4]tolerations:[]# If this is set to true, the operator will define a PersistentVolumeClaim template# on the QuarksStatefulSet of the instance group, and it will use that PVC for all volume# mounts for ephemeral disksephemeralAsPVC:false# This sets the backoffLimit for the jobs running errands. If not set, it will use the Kube default which is 6.# https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/#handling-pod-and-container-failuresjobBackoffLimit:6# An array of disks to be mounted on the containersdisks:# A PersistentVolumeClaim to be used as a template in the StatefulSet of the instance group.-pvc:name:foostorageClassName:persistent# Volume definition to be included in the pod.volume:name:extravolumeemptyDir:{}# Volume mounts to be set on the containers that match the job and process set in \"filters\".volumeMount:name:extravolumemountPath:/var/vcap/data/rep# Filters to identify on which containers to apply the volume mounts.filters:job_name:\"cflinuxfs3-rootfs-setup\"process_name:\"test-server\"# Each addon job is added to the desired manifest before it's persisted# Not all placement rules are supported, see below for more details.addons:# The name of the addon is not used by the operator.# TODO: investigate whether it's useful to set this in an annotation of the instance group sts/pod-name:foo# All jobs are added to instance groups based on placement rules before the desired manifest is persistedjobs:-name:metronrelease:loggregator-releaseproperties:loggregator:metron:log_level:debuginclude:# Supportedstemcell:-os:opensuse# Not supported, addons are used per-deploymentdeployments:[]# Supportedjobs:name:cloud_controller_ngrelease:capi-release# Supportedinstance_groups:-api-diego-cell# Not supportednetworks:[]# Not supportedteams:[]# The same matchers are supported as the \"include\" keyexclude:{}# Deprecated - the cf-operator does not support this key.# An error is thrown if this is set.properties:{}# For each variable, the cf-operator creates QuarksSecrets# As with normal BOSH, variables are referenced by job properties.# Each variable's generated secret is mounted in the container that renders each job's# templates. They are then used by the rendering process.# This means that the operator needs to look at the job's properties, and parse any references# to variables, so it knows what it needs to mount.variables:# Unique name used to identify a variable. Used to name the QuarksSecret-name:\"adminPass\"# As with normal BOSH, supported types are certificate, password, rsa, and ssh.type:\"password\"# Specifies generation optionsoptions:{is_ca:true,common_name:\"some-ca\"}# Tags are transformed into annotations for the resources created# by this deployment.tags:maintainer:\"Philip J. Fry\"    [1] https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names [2] https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/ [3] https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity [4] https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/  BPM In a BOSH release some jobs have BPM configuration in templates/bpm.yml.erb. Each process specified in the BPM configuration is run in a single Kubernetes Container as part of a Pod.\nThe following subsections describe the mapping of BPM configuration into containers.\nEntrypoint \u0026 Environment Variables    Bosh Kube Pod Container     executable command   args args   env env    Resources    Bosh Kube Pod Container     workdir workingDir. Not implemented yet.   hooks initContainers. and container hooks. Not implemented yet.   process.capabilities container.SecurityContext.Capabilities.   limits container.Resources.Limits. Not implemented yet.   ephemeral_disk emptyDir volumes by default, but can be PersistentVolumeClaims if ephemeralAsPVC is set on the bosh.agent.settings.   persistent_disk PersistentVolumeClaims. Not yet implemented.   additional_volumes emptyDir. Paths under /var/vcap/store are currently ignored.   unsafe.unrestricted_volumes emptyDir. Paths under /var/vcap/store are currently ignored.   unsafe.privileged container.SecurityContext.Privileged.    If you are looking for limits and resource request for BPM processes, see this section of the documentation.\nHealth checks BPM doesn’t provide information for health checks and relies on monit instead. CF-Operator provides health checks via the quarks property key in the deployment manifest.\nIn Kubernetes, we use liveness and readiness probes for healthchecks.\nHooks BPM supports pre_start hooks. CF-Operator will convert those to additional init containers.\nConversion Details Calculation of docker image location for releases Release image tags are immutable. The release image locations are comprised of multiple elements:\n docker registry URL organization and repository stemcell name and version fissile version the release name and version  Release image locations always have to be resolved in the context of an instance group/job because they depend on the stemcell that is being used.\nA typical release image location looks could look like hub.docker.com/cfcontainerization/cflinuxfs3-release:opensuse-15.0-28.g837c5b3-30.263-7.0.0_233.gde0accd0-0.62.0.\nThe different elements are taken from different places in the manifest. Given this excerpt from a BOSH deployment manifest:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  stemcells:-alias:defaultos:opensuse-42.3version:28.g837c5b3-30.263-7.0.0_234.gcd7d1132instance_groups:-name:diego-cellstemcell:defaultjobs:-name:cflinuxfs3-rootfs-setuprelease:cflinuxfs3releases:-name:cflinuxfs3version:0.62.0url:hub.docker.com/cfcontainerizationsha1:6466c44827c3493645ca34b084e7c21de23272b4stemcell:os:opensuse-15.0version:28.g837c5b3-30.263-7.0.0_233.gde0accd0   The stemcell information (name, and stemcell and fissile version) are taken from the stemcells entry that matches the instance group’s stemcell alias. The registry URL including the organization, the release name, and the version come from the releases entry that’s referenced from the job.\n Note:\nReleases can optionally specify a separate stemcell section, in which case the information from the instance group stemcell is overridden.\n Variables to Quarks Secrets For each Explicit BOSH Variable (with a definition in the variables section in the deployment manifest), the cf-operator creates an QuarksSecret. The QuarksSecret is meant to generate the value required by the variable.\nThe name of the QuarksSecret is calculated like this:\n1  var-\u003cVARIABLE_NAME\u003e   The name of the final generated Secret (the secretName key of the QuarksSecret) is calculated the same way.\nOverriding generated variables The user can also specify overrides for generated secrets using the vars key in the BOSHDeployment spec.\nThese map explicit variable names to secret names.\nEach secret must contain the usual keys used in explicit variables (see here for more details).\nYou can find an example here.\nInstance Groups to Quarks StatefulSets and Jobs BOSH Services vs BOSH Errands BOSH Services are converted to QuarksStatefulSets and Services.\nBOSH Errands are converted to QuarksJobs with trigger.strategy: manually.\nBOSH Auto-Errands (supported only by the operator) are converted to QuarksJobs with trigger.strategy: once.\nMiscellaneous Dealing with AZs QuarksStatefulSets support AZs. You can learn more about this in the docs.\nIf you don’t want to use AZs, remove the key. Otherwise AZ names in the BOSH manifest correspond to the “failure-domain.beta.kubernetes.io/zone” labels that are set on the nodes.\nSupport for active/passive pod replicas QuarksStatefulSets support active/passive pod replicas. You can learn more about this in the docs.\nEphemeral Disks We use an emptyDir for ephemeral disks. You can learn more from the official docs.\nIf the setting bosh.settings.agent.ephemeralAsPVC is set to true, the operator will use PersistentVolumeClaims instead. This option should be used for jobs that make assumptions about ephemeral disks (like this garden job) mounts, or the size limit for the disk is critical. If vm_resources.ephemeral_disk_size is set, the PVC size will be set to this. If it’s not set, the operator will try to use persistent_disk as a size. If this is not set either, the operator will use a default of 10GB.\nCredentials for Docker Registries Providing credentials for private registries is supported by Kubernetes. Please read the official docs.\nRunning manual errands BOSH makes use of errands, which are manually triggered. We support manual triggers - you can learn more in the QuarksJob docs.\nReadiness and Liveness Probes When the deployment manifest declares health check information for jobs, via the quarks section, we configure those in Kubernetes.\nThe probes are defined per BPM process.\nExample:\n1 2 3 4 5 6 7 8 9 10  instance_groups:-name:\"api-az1\"process.properties:quarks:run:healthcheck:bpm-process-name:readiness:liveness:   Both keys contain information that should is used as-is for the container that matches the process name.\nPersistent Disks When a BOSH deployment manifest declares persistent disks on instance groups, we provide a persistent volume to the containers of a pod in /var/vcap/store. You can learn more about BOSH Persistent Disks in the BOSH Official Docs.\nThese volumes are mounted on each container that’s part of the instance group.\nThe implementation uses the default storage class if not specified using the persistent_disk_type key in the manifest.\nManual (“implicit”) variables BOSH deployment manifests support two different types of variables, implicit and explicit ones.\n“Explicit” variables are declared in the variables section of the manifest and are generated automatically before the interpolation step.\n“Implicit” variables just appear in the document within double parentheses without any declaration. These variables have to be provided by the user prior to creating the BOSH deployment as a secret. The secret name has to follow the scheme\n1  var-\u003cvariable-name\u003e   By default the variable content is expected in the value key, e.g.\n((system-domain))  1 2 3 4 5 6 7 8  ---apiVersion:v1kind:Secretmetadata:name:var-system-domaintype:OpaquestringData:value:example.com   It is also possible to specify the key name after a / separator, e.g.\n((ssl/ca))  1 2 3 4 5 6 7 8 9 10  ---apiVersion:v1kind:Secretmetadata:name:var-ssltype:OpaquestringData:ca:...cert:...key:...   Pre_render_scripts Similar to what can be achieved in SCF v1, with the patches scripts, the cf-operator is able to support this behaviour. Basically, it allows the user to execute a custom script during runtime of the job container for a specific instance_group. Because patching during runtime is always a great feature to have, for a variety of reasons, users can specify this via the quarks.pre_render_scripts key.\nKeep it mind, that the script should belong to a type, to avoid running all scripts as a whole. Currently supported types are:\n quarks.pre_render_scripts.bpm. quarks.pre_render_scripts.ig_resolver quarks.pre_render_scripts.jobs  This allows you to run anything, by specifying a list of commands/scripts to execute. For example:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  instance_groups: - name: redis-slave instances: 2 lifecycle: errand azs: [z1, z2] jobs: - name: redis-server release: redis properties: quarks: pre_render_scripts: bpm: - | touch /tmp   BOSH DNS The BOSH DNS addon is implemented using a separate DNS server (coredns). For each BOSHDeployment, which enables this addon, an additional DNS server is created within the namespace. This DNS server rewrites all BOSH dns requests to standard k8s queries (e.g. api.service.cf.internal -\u003e api.\u003cnamespace\u003e.svc.cluster.local) and forwards them to the k8s DNS server. All pods created from the BOSHDeployment are configured to use this DNS server.\nAdditionally the headless services are created on base of the specified aliases. The following alias\n1 2 3 4 5 6 7  -domain:blobstore.service.cf.internaltargets:-deployment:cfdomain:boshinstance_group:singleton-blobstorenetwork:defaultquery:'*'   will create a headless service with the name blobstore instead of singleton-blobstore.\nFor migration purpose, the DNS service does also a rewrite of all previous headless service names (e.g. singleton-blobstore is rewritten to blobstore.\u003cnamespace\u003e.svc.cluster.local).\nFlow Naming Conventions After creating a BOSHDeployment named nats-deployment, with one Instance Group, the following resources should exist:\n BOSHDeployment\n1  nats-deployment   QuarksJob\n1 2  ig dm   QuarksSecret\n1  var-nats-password   QuarksStatefulSet\n1  nats   Secrets\n1 2 3 4 5  bpm.nats-v1 ig-resolved.nats-v1 var-nats-password with-ops desired-manifest-v1   StatefulSets\n1  nats   Pods\n1 2  nats-0 nats-1   Services\n1 2 3  nats nats-0 nats-1    ","excerpt":" High-level Direction  releases are defined in the usual way (a …","ref":"/docs/core-tasks/from_bosh_to_kube/","title":"From BOSH to Kubernetes"},{"body":" About Operators Framework: Controller Runtime  Kubebuilder docs controller-runtime docs  Operator Pattern \u0026 Features  Operator pattern\n Kubernetes Custom Resource Controller The Kubernetes Operator Pattern  Admission webhooks and eventing\n Sample Webhook Custom Resource Definitions  Finalizers\n Finalizers - Official Docs Using Finalizers  Watches\n Controller Watches  Generate resources\n Code Generation for Custom Resources  Apply CRD\n Extending Kubernetes APIs using CRDs   Operator Examples  Elastic Search Operator Postgres Operator Tensorflow Operator NATS Operator Knative Sample controller  Extending Kubernetes  Controller pattern Custom controllers CRD openAPI validation Kubernetes primitives (ebook)  Testing  Kubernetes docs Kubernetes fakes Magic tricks of testing  ","excerpt":" About Operators Framework: Controller Runtime  Kubebuilder docs …","ref":"/docs/concepts/about_operators/","title":"About operators"},{"body":" BOSHDeployment  BOSHDeployment  Description BDPL Component  BOSHDeployment Controller  Watches Reconciliation Highlights  Generate Variables Controller  Watches Reconciliation Highlights  BPM Controller  Watches Reconciliation Highlights   BDPL Abstract view BOSHDeployment resource examples [BOSHDeployment status][#boshdeployment-status]   Description A BOSH deployment is created from a deployment manifest and optionally ops files.\nThe deployment manifest is based on a vanilla BOSH deployment manifest. The ops files modify the deployment manifest. For example, ops files can be used to replace release tarballs with docker images, thus enabling deployment on Kubernetes.\nA deployment is represented by the boshdeployments.quarks.cloudfoundry.org (bdpl) custom resource, defined in boshdeployment_crd.yaml. This bdpl custom resource contains references to config maps or secrets containing the actual manifests content.\nThe name of the bdpl resource is the deployment name. The name in the BOSH manifest is ignored.\nAfter creating the bdpl resource on Kubernetes, i.e. via kubectl apply, the CF operator will start reconciliation, which will eventually result in the deployment of the BOSH release on Kubernetes.\nBDPL Component The BOSHDeployment component is a categorization of a set of controllers, under the same group. Inside the BDPL component we have a set of 3 controllers together with one separate reconciliation loop per controller to deal with BOSH deployments(end user input)\nFigure 1 is a BDPL component diagram that covers the set of controllers it uses and their relationship with other components(e.g. QuarksJob, QuarksSecret and QuarksStatefulSet)\nFig. 1: The BOSHDeployment component\nFigure 1 illustrates a couple of things. Firstly, at the very top, we have the cf-operator , which is a long running application with a namespaced scope. When the cf-operator pod is initialized it will automatically register all controllers with the Kubernetes Controller Manager.\nWhile at a first glance the above diagram looks complex, it can be explained easily by focusing on each controller´s main functions: Reconciliation \u0026 Watch.\nBOSHDeployment Controller Fig. 2: The BOSHDeployment controller\nThis is the controller that manages the end user input(a BOSH manifest).\nWatches in BDPL controller  BOSHDeployment: Create ConfigMaps: Update Secrets: Create and Update  Reconciliation in BDPL controller  generates .with-ops secret, that contains the deployment manifest, with all ops files applied generates variable interpolation QuarksJob resource generates data gathering QuarksJob resource generates BPM configuration QuarksJob resource  Highlights in BDPL controller Transform the concepts of BOSH into Kubernetes resources:\n BOSH errands to QuarksJob CRD instances BOSH instance_groups to QuarksStatefulSet CRD instances BOSH variables to QuarksSecret CRD instance  All of the three created QuarksJob instances will eventually persist their STDOUT into new secrets under the same namespace.\n The output of the variable interpolation QuarksJob ends up as the .desired-manifest-v1 secret, which is a versioned secret. At the same time this secret serves as the input for the data gathering QuarksJob. The output of the data gathering QuarksJob, ends up as the .ig-resolved.\u003cinstance_group_name\u003e-v1 versioned secret. The output of the BPM configuration QuarksJob, ends up as the bpm.\u003cinstance_group_name\u003e-v1 versioned secret.  Generate Variables Controller Fig. 3: The Generated Variables controller\nThis is the controller that is responsible for auto-generating certificates, passwords and other secrets declared in the manifest. In other words, it translates all BOSH variables into custom Kubernetes primitive resources. It does this with the help of QuarksSecrets. It watches the .with-ops secret, retrieves the list of BOSH variables and triggers the generation of QuarksSecrets per item in that list.\nWatches in GV controller  Secrets: Create and Update.  Reconciliation in GV controller  generates QuarksSecrets resources.  Highlights in GV controller The secrets resources, generated by these QuarksSecrets are referenced by the variable interpolation QuarksJob. When these secrets are created/updated, the variable interpolation QuarksJob is run.\nBPM Controller Fig. 4: The BPM controller\nThe BPM controller has the responsibility to generate Kubernetes resources per instance_group. It is triggered for each instance_group in the desired manifest, since we generate one BPM Secret for each. The reconciler starts each instance_group as its corresponding secret is created. It does not wait for all secrets to be ready.\nWatches in BPM controller  versioned secrets: Create and Update.  Reconciliation in BPM controller  Render BPM resources per instance_group Convert instance_groups of the type services to QuarksStafulSet resources. Convert instance_groups of the type errand to QuarksJob resources. Generates Kubernetes services that will expose ports for the instance_groups Generate require PVC´s.  Highlights in BPM controller The Secrets watched by the BPM Reconciler are Versioned Secrets.\nResources are applied using an upsert technique implementation.\nAny resources that are no longer required are deleted.\nAs the BOSHDeployment is deleted, all owned resources are automatically deleted in a cascading fashion.\nPersistent volumes are left behind.\nBDPL Abstract view Figure 5 is a diagram that explains the whole BOSHDeployment component controllers flow, in a more high level perspective.\nedit Fig. 5: The BOSHDeployment component controllers interactions\nBOSHDeployment resource examples See https://github.com/cloudfoundry-incubator/cf-operator/tree/master/docs/examples/bosh-deployment\nBOSHDeployment status The BOSHDeployment status is resolved by a separate controller which tracks the status of QuarksJob and QuarksStatefulSet associated with a deployment. The controller annotates the instance groups and the jobs counters and it resolves the BDPL State (Deployed, Converting , Resolving) by looking at the associated resources states and computing the overall state.\nThe BOSHDeployment status spec is composed of the following fields:\n1 2 3 4 5 6 7 8 9 10 11 12  // BOSHDeploymentStatus defines the observed state of BOSHDeployment type BOSHDeploymentStatus struct { // Timestamp for the last reconcile \tLastReconcile *metav1.Time `json:\"lastReconcile\"` State string `json:\"state\"` Message string `json:\"message\"` TotalJobCount int `json:\"totalJobCount\"` CompletedJobCount int `json:\"completedJobCount\"` TotalInstanceGroups int `json:\"totalInstanceGroups\"` DeployedInstanceGroups int `json:\"deployedInstanceGroups\"` StateTimestamp *metav1.Time `json:\"stateTimestamp\"` }   The BOSHDeployment States can be:\n Created Converting to Kubernetes Resources Resolving Manifest Deployed  where “Deployed” is the final state. Note that during deployments, the lifecycle might vary if the same resources are updated subsequently: the status of a BOSHDeployment may go back from Deployed to Converting and Resolving again if updates to the manifest are triggered.\nThe Reconcile resolves to the Deployed state by looking at the overall counts of QuarksJobs and QuarksStatefulSet associated to the BOSHDeployment and its state:\n Converting: All QuarksJobs belonging to a BOSHDeployment are completed, but QuarksStatefulSet aren’t ready yet ( or either way around ) Resolving: QuarksJobs belonging to a BOSHDeployment aren’t completed, QuarksStatefulSet aren’t ready yet Deployed: All QuarksJobs and QuarksStatefulSet are ready/completed.  ","excerpt":" BOSHDeployment  BOSHDeployment  Description BDPL Component …","ref":"/docs/development/controllers/bosh_deployment/","title":"Bosh Deployment"},{"body":"It is possible to define resource requests and limits (CPU/Memory) for each container generated by the Quarks Operator.\nThe Quarks-operator, while converting the BPM informations, translates the BPM processes requests and limits to Kubernetes containers and pods, which are generated from instance groups.\nIt expands the BOSH specification to cover the features offered by Kubernetes, here is a complete example:\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62  ---apiVersion:v1kind:ConfigMapmetadata:name:ops-scaledata:ops:| - type: replacepath:/instance_groups/name=quarks-gora?/instancesvalue:2---apiVersion:v1kind:ConfigMapmetadata:name:quarks-gora-manifestdata:manifest:| ---name:quarks-gora-deploymentreleases:-name:quarks-goraversion:\"0.0.7\"url:docker.io/cfcontainerizationstemcell:os:SLE_15_SP1-26.5version:7.0.0_374.gb8e8e6afinstance_groups:-name:quarks-gorainstances:1jobs:-name:quarks-gorarelease:quarks-goraproperties:quarks-gora:port:55556ssl:falsequarks:ports:-name:\"quarks-gora\"protocol:\"TCP\"internal:55556bpm:processes:-name:quarks-gorarequests:cpu:\"2m\"memory:\"128Mi\"limits:cpu:\"4\"memory:\"2Gi\"---apiVersion:quarks.cloudfoundry.org/v1alpha1kind:BOSHDeploymentmetadata:name:quarks-gora-deploymentspec:manifest:name:quarks-gora-manifesttype:configmapops:-name:ops-scaletype:configmap    Complete source code: https://github.com/cloudfoundry-incubator/quarks-operator/blob/master/docs/examples/bosh-deployment/quarks-gora-cpu-mem.yaml   Here is a comprehensive table of the conversion which is done by the Quarks-operator and the respective Kubernetes equivalent:\n   Job spec in Manifest Kube Pod Container Description     properties.quarks.bpm.processes[n].requests.cpu container.Resources.Requests.cpu Guaranteed CPU   properties.quarks.bpm.processes[n].requests.memory container.Resources.Requests.memory Guaranteed memory   properties.quarks.bpm.processes[n].limits.cpu container.Resources.Limits.cpu Specify a CPU request and a CPU limit   properties.quarks.bpm.processes[n].limits.memory container.Resources.Limits.memory Specify a memory request and a memory limit    ","excerpt":"It is possible to define resource requests and limits (CPU/Memory) for …","ref":"/docs/features/resources_limit/","title":"BOSH resource requests and limit"},{"body":" BOSH releases consume two types of variables, explicit and implicit ones.\nImplicit Variables Implicit variables have to be created before creating a BOSH deployment resource. The example creates a secret named var-custom-password. That value will be used to fill ((custom-password)) place holders in the BOSH manifest.\nThe name of the secret has to follow this scheme: ‘var-‘\nMissing implicit variables are treated as an error.\nExplicit Variables Explicit variables are explicitly defined in the BOSH manifest. They are generated automatically upon deployment and stored in secrets.\nThe naming scheme is the same as for implicit variables.\nIf an explicit variable secret already exists, it will not be generated. This allows users to set their own passwords, etc.\n","excerpt":" BOSH releases consume two types of variables, explicit and implicit …","ref":"/docs/features/variables/","title":"BOSH Variables"},{"body":"","excerpt":"","ref":"/docs/concepts/","title":"Concepts"},{"body":" The quarks-operator watches four different types of custom resources:\n BoshDeployment QuarksJob QuarksSecret QuarksStatefulSet  The cf-operator requires the according CRDs to be installed in the cluster in order to work as expected. By default, the cf-operator applies CRDs in your cluster automatically.\nTo verify that the CRD´s are installed:\n1 2 3 4 5 6  $ kubectl get crds NAME CREATED AT boshdeployments.quarks.cloudfoundry.org 2019-06-25T07:08:37Z quarksjobs.quarks.cloudfoundry.org 2019-06-25T07:08:37Z quarkssecrets.quarks.cloudfoundry.org 2019-06-25T07:08:37Z quarksstatefulsets.quarks.cloudfoundry.org 2019-06-25T07:08:37Z   Architecture design Draw.io with the sources for the quarks_deployment_flow-*png controller charts:\nhttps://drive.google.com/file/d/1Uk2h5pOmY-gLtbfpDNO3POTcqI5UdZgj/view?usp=sharing\n","excerpt":" The quarks-operator watches four different types of custom resources: …","ref":"/docs/development/controllers/","title":"Kubernetes Controllers"},{"body":"  bdv1.LabelDeploymentName “quarks.cloudfoundry.org/deployment-name” bdv1.LabelDeploymentSecretType “quarks.cloudfoundry.org/secret-type” bdv1.LabelDeploymentVersion “quarks.cloudfoundry.org/deployment-version” bdv1.LabelInstanceGroupName “quarks.cloudfoundry.org/instance-group-name” bdv1.LabelReferencedJobName “quarks.cloudfoundry.org/referenced-job-name” qstsv1a1.LabelAZIndex “quarks.cloudfoundry.org/az-index” qstsv1a1.LabelAZName “quarks.cloudfoundry.org/az-name” qstsv1a1.LabelActivePod “quarks.cloudfoundry.org/pod-active” qstsv1a1.LabelPodOrdinal “quarks.cloudfoundry.org/pod-ordinal” qstsv1a1.LabelQStsName “quarks.cloudfoundry.org/quarks-statefulset-name” qsv1a1.LabelKind “quarks.cloudfoundry.org/secret-kind” delete = pod variableName app  Data From Tests ConfigMaps Secret Rotation ConfigMap quarks.cloudfoundry.org/secret-rotation = yes  QJob quarks.cloudfoundry.org/deployment-name = bosh-manifest-two-instance-groups delete=pod quarks.cloudfoundry.org/deployment-version = 1 quarks.cloudfoundry.org/instance-group-name = nats-smoke-tests  QJob Job quarks.cloudfoundry.org/qjob-name = ig-bosh-manifest-two-instance-groups  Pod from Job delete=pod quarks.cloudfoundry.org/qjob-name=dm-test  QSTS quarks.cloudfoundry.org/deployment-name = test quarks.cloudfoundry.org/deployment-version = 1 quarks.cloudfoundry.org/instance-group-name = nats  STS quarks.cloudfoundry.org/az-index=0 quarks.cloudfoundry.org/deployment-name=test quarks.cloudfoundry.org/instance-group-name=nats quarks.cloudfoundry.org/quarks-statefulset-name=test-nats  STS Pod quarks.cloudfoundry.org/az-index=0 quarks.cloudfoundry.org/deployment-name=test quarks.cloudfoundry.org/instance-group-name=nats quarks.cloudfoundry.org/pod-active=active|true quarks.cloudfoundry.org/pod-ordinal=0 quarks.cloudfoundry.org/quarks-statefulset-name=test-nats  Service quarks.cloudfoundry.org/az-index=0 quarks.cloudfoundry.org/deployment-name=test quarks.cloudfoundry.org/instance-group-name=nats quarks.cloudfoundry.org/pod-ordinal=0  QSec quarks.cloudfoundry.org/deployment-name = test variableName = nats_password  QSec Secret quarks.cloudfoundry.org/secret-kind=generated  Secrets WithOps Secrets quarks.cloudfoundry.org/deployment-name=test quarks.cloudfoundry.org/secret-type=with-ops  Desired Manifest Secret quarks.cloudfoundry.org/container-name=desired-manifest quarks.cloudfoundry.org/deployment-name=test quarks.cloudfoundry.org/entanglement=testdesired-manifest quarks.cloudfoundry.org/referenced-job-name=instance-group-test quarks.cloudfoundry.org/secret-kind=versionedSecret quarks.cloudfoundry.org/secret-type=desired quarks.cloudfoundry.org/secret-version=1  BPM Secret quarks.cloudfoundry.org/container-name=nats quarks.cloudfoundry.org/deployment-name=test quarks.cloudfoundry.org/entanglement=testbpmnats quarks.cloudfoundry.org/remote-id=nats quarks.cloudfoundry.org/secret-kind=versionedSecret quarks.cloudfoundry.org/secret-type=bpm quarks.cloudfoundry.org/secret-version=1  IG Resolved Secret quarks.cloudfoundry.org/container-name=nats quarks.cloudfoundry.org/deployment-name=test quarks.cloudfoundry.org/entanglement=testig-resolvednats quarks.cloudfoundry.org/remote-id=nats quarks.cloudfoundry.org/secret-kind=versionedSecret quarks.cloudfoundry.org/secret-type=ig-resolved quarks.cloudfoundry.org/secret-version=1  Link Secret quarks.cloudfoundry.org/container-name=nats quarks.cloudfoundry.org/deployment-name=test quarks.cloudfoundry.org/entanglement=link-test-nats-nats quarks.cloudfoundry.org/remote-id=nats  ","excerpt":"  bdv1.LabelDeploymentName “quarks.cloudfoundry.org/deployment-name” …","ref":"/docs/development/labels/","title":"Labels"},{"body":" The CF-Operator is a Cloud Foundry Incubating Project.\n cf-operator enables the deployment of BOSH Releases, especially Cloud Foundry, to Kubernetes.\nIt’s implemented as a k8s operator, an active controller component which acts upon custom k8s resources.\n Installation notes Incubation Proposal: Containerizing Cloud Foundry Slack: #quarks-dev on https://slack.cloudfoundry.org Backlog: Pivotal Tracker Docker: https://hub.docker.com/r/cfcontainerization/cf-operator/tags  ","excerpt":" The CF-Operator is a Cloud Foundry Incubating Project.\n cf-operator …","ref":"/docs/concepts/operator/","title":"Cloud Foundry Operator"},{"body":"Project Quarks is an incubating effort within the Cloud Foundry Foundation that packages Cloud Foundry Application Runtime as containers instead of virtual machines, enabling easy deployment to Kubernetes.\nThe resulting containerized CFAR provides an identical developer experience to that of BOSH-managed Cloud Foundry installations, requires less infrastructure capacity and delivers an operational experience that is familiar to Kubernetes operators.\n","excerpt":"Project Quarks is an incubating effort within the Cloud Foundry …","ref":"/docs/concepts/quarks/","title":"Project Quarks"},{"body":"  QuarksJob  QuarksJob Component  Errand Controller  Watches Reconciliation Highlights  Job Controller  Watches Reconciliation Highlights   Relationship with the BDPL component QuarksJob Examples   Description The QuarksJob component is a categorization of a set of controllers, under the same group. Inside the QuarksJob component we have a set of 2 controllers together with one separate reconciliation loop per controller.\nFigure 1, illustrates the QuarksJob component diagram and the set of controllers it uses.\nFig. 1: The QuarksJob component\nErrand Controller Fig. 2: The Errand controller flow\nThis is the controller responsible for implementing Errands, this will lead to the generation of a Kubernetes job, in order to complete a task.\nWatches in Errand controller  QuarksJob resources: Create and Update ConfigMaps: Update Secrets: Create and Update  Reconciliation in Errand controller  When an QuarksJob instance is generated, it will create an associated Kubernetes Job. The generation of new Kubernetes Jobs also serves as the trigger for the Job Controller, to start the Reconciliation.  Job Controller Fig. 3: The Job controller flow\nThis is an auxiliary controller that relies on the Errand Controller output. It will be watching for Kubernetes Jobs that have Succeeded and deletes the job. If the jobpod of the succeeded job has a label delete=pod, it deletes the job pod too.\nWatches in job controller  Jobs: Succeeded  Reconciliation in job controller  Deletes succeeded job and its pod.  Relationship with the BDPL component Fig. 4: Relationship between the BDPL controller and the QuarksJob component\nFigure 4 illustrates the interaction of the BOSHDeployment Controller with the Errand Controller and how the output of this one serves as the trigger for the Job Controller.\nQuarksJob Examples See https://github.com/cloudfoundry-incubator/quarks-job/tree/master/docs/examples\n","excerpt":"  QuarksJob  QuarksJob Component  Errand Controller  Watches …","ref":"/docs/development/controllers/quarksjob/","title":"Quarks Job"},{"body":" Description The QuarksRestart controller is responsible for restarting kubernetes resources such as StatefulSet and Deployment. They are restarted whenever a secret referenced by these resources gets updated.\nThis feature also enables updating entangled pods whenever the link secrets get updated.\nWatches in Quarks Restart Controller  Secret: Restart pods that have the annotation quarks.cloudfoundry.org/restart-on-update  Reconciliation in Quarks Restart Controller  adds restart annotation quarks.cloudfoundry.org/restart to StatefulSet or Deployment as appropriate.  QuarksRestart Examples See https://github.com/cloudfoundry-incubator/cf-operator/tree/master/docs/examples/quarks-restart\n","excerpt":" Description The QuarksRestart controller is responsible for …","ref":"/docs/development/controllers/quarks_restart/","title":"Quarks restart"},{"body":"  QuarksSecret  Description QuarksSecret Component QuarksSecret Controller  Watches in Quarks Secret Controller Reconciliation in Quarks Secret Controller Highlights in Quarks Secret Controller Types Auto-approving Certificates Copies  CertificateSigningRequest Controller  Watches in CSR Controller Reconciliation in CSR Controller Highlights in CSR Controller  SecretRotation Controller  Watches in Secret Rotation Controller Reconciliation in Secret Rotation Controller  Relationship With the BDPL Component QuarksSecret Examples   Description A QuarksSecret generates passwords, keys and certificates and stores them in Kubernetes secrets.\nQuarksSecret Component The QuarksSecret component consists of three controllers, each with a separate reconciliation loop.\nFigure 1, illustrates the component and associated set of controllers.\nFig. 1: The QuarksSecret component\nQuarksSecret Controller Fig. 2: The QuarksSecret controller\nWatches in Quarks Secret Controller  QuarksSecret: Creation QuarksSecret: Updates if .status.generated is false  Reconciliation in Quarks Secret Controller  generates Kubernetes secret of specific types(see Types under Highlights). generate a Certificate Signing Request against the cluster API. sets .status.generated to true, to avoid re-generation and allow secret rotation.  Highlights in Quarks Secret Controller Types Depending on the spec.type, QuarksSecret supports generating the following:\n   Secret Type spec.type certificate.signerType certificate.isCA     passwords password not set not set   username-password pairs basic-auth not set not set   rsa keys rsa not set not set   ssh keys ssh not set not set   self-signed root certificates certificate local true   self-signed certificates certificate local false   cluster-signed certificates certificate cluster false     Note:\nYou can find more details in the BOSH docs.\n Auto-approving Certificates A certificate QuarksSecret can be signed by the Kubernetes API Server. The QuarksSecret Controller is responsible for generating the certificate signing request:\n1 2 3 4 5 6 7 8 9  apiVersion:certificates.k8s.io/v1beta1kind:CertificateSigningRequestmetadata:name:generate-certificatespec:request:((encoded-cert-signing-request))usages:-digitalsignature-keyencipherment   Copies The QuarksSecret controller can create copies of a generated secret across multiple namespaces, as long as the target secrets (that live in a namespace other than the namespace of the QuarksSecret) already exist, and have an annotation of:\n1  quarks.cloudfoundry.org/secret-copy-of: NAMESPACE/generate-password-with-copies   as well as the usual label for generated secrets:\n1  quarks.cloudfoundry.org/secret-kind: generated   This ensures that the creator of the QuarksSecret must have access to the copy target namespace.\nCopied Secrets do not have an owner set, and are not cleaned up automatically when the QuarksSecret is deleted.\nCertificateSigningRequest Controller Fig. 3: The CertificateSigningRequest controller\nWatches in CSR Controller  Certificate Signing Request: Creation  Reconciliation in CSR Controller  once the request is approved by Kubernetes API, will generate a certificate stored in a Kubernetes secret, that is recognized by the cluster.  Highlights in CSR Controller The CertificateSigningRequest controller watches for CertificateSigningRequest and approves QuarksSecret-owned CSRs and persists the generated certificate.\nSecretRotation Controller The secret rotation controller watches for a rotation config map and re-generates all the listed QuarksSecrets.\nWatches in Secret Rotation Controller  ConfigMap: Creation of a config map, which has the secret-rotation label.  Reconciliation in Secret Rotation Controller  Will read the array of QuarksSecret names from the JSON under the config map key secrets. Skip QuarksSecret where .status.generated is false, as these might be under control of the user. Set .status.generated for each named QuarksSecret to false, to trigger re-creation of the corresponding secret.  Relationship With the BDPL Component All explicit variables of a BOSH manifest will be created as QuarksSecret instances, which will trigger the QuarksSecret Controller. This will create corresponding secrets. If the user decides to change a secret, the .status.generated field in the corresponding QuarksSecret should be set to false, to protect against overwriting.\nQuarksSecret Examples See https://github.com/cloudfoundry-incubator/quarks-secret/tree/master/docs/examples\n","excerpt":"  QuarksSecret  Description QuarksSecret Component QuarksSecret …","ref":"/docs/development/controllers/quarks_secret/","title":"Quarks Secret"},{"body":"  QuarksStatefulSet  Description QuarksStatefulSet Component  QuarksStatefulSet Controller  Watches Reconciliation Scaling Restrictions (not implemented) Automatic Restart of Containers Exposing QuarksStatefulSets Publicly Cluster IP Load Balancer Ingress Extended Upgrade Support Detects if StatefulSet versions are running AZ Support Tolerations  QuarksStatefulSet Active-Passive Controller  Relationship with the BPM component QuarksStatefulSet Examples   Description The QuarksStatefulSet component can be understood as the set of controllers responsible for translating the BOSH manifest instance_groups into Kubernetes resources.\nQuarksStatefulset Component The QuarksStatefulset component is a categorization of a set of controllers, under the same group. Inside the QuarksStatefulset component, we have a set of 2 controllers together with one separate reconciliation loop per controller.\nFigure 1 illustrates a QuarksStatefulset component diagram that covers the set of controllers it uses.\nFig. 1: The QuarksStatefulset component\nQuarksStatefulSet Controller Fig. 2: The QuarksStatefulset controller\nThis controller will generate a Kubernetes statefulset for each instance_group defined in the BOSH manifest. This Statefulset will also include a set of Kubernetes services, so that each component can be accessed on specific ports.\nWatches in sts controller  QuarksStatefulset: Creation Configmaps: Update Secrets: Update  Reconciliation in sts controller Will generate versioned Statefulsets with the required data to make all jobs of the instance_group runnable.\nScaling Restrictions (not implemented) Ability to set restrictions on how scaling can occur: min, max, odd replicas.\nAutomatic Restart of Containers When an env value or mount changes due to a ConfigMap or Secret change, containers are restarted. The operator watches all the ConfigMaps and Secrets referenced by the StatefulSet, and automatically performs the update, without extra workarounds.\nExposing QuarksStatefulSets Publicly Exposing quarksstatefulsets is similar to exposing statefulsets in kubernetes. A Kubernetes service makes use of labels to select the pods which should be in the service. We need to use two labels to group the pods of a single instance group.\n quarks.cloudfoundry.org/instance-group-name: ((instanceGroupName)) quarks.cloudfoundry.org/deployment-name: ((deploymentName))  Cluster IP Following is the example which creates a service with type ClusterIP for a single instance group named nats in deployment nats-deployment for exposing port 4222.\n1 2 3 4 5 6 7 8 9 10 11 12 13  apiVersion:v1kind:Servicemetadata:name:nats-servicespec:type:ClusterIPselector:quarks.cloudfoundry.org/instance-group-name:natsquarks.cloudfoundry.org/deployment-name:nats-deploymentports:-protocol:TCPport:80targetPort:4222   Complete example can be found here.\nThough, by default, quarks creates three services of type ClusterIP as defined here for any instance group.\nLoad Balancer For creating a service type LoadBalancer, we just need to change the .spec.type to LoadBalancer in the above example. The LoadBalancer Ingress is your public IP specified in the output of this command kubectl describe service nats-service.\nIngress Ingress doesn’t use any labels but just sits on top of services and acts as a smart router. You can create services of different types based on the above examples and use them as values in the ingress Kubernetes spec. An example of Ingress can be found here\nFor more information about Kubernetes services, we recommend you to read this.\nExtended Upgrade Support When an update needs to happen, a second StatefulSet for the new version is deployed, and both coexist until canary conditions are met.\nAnnotated with a version (auto-incremented on each update). The annotation key is quarks.cloudfoundry.org/version.\nAbility to upgrade even though StatefulSet pods are not ready.\nDetects if StatefulSet versions are running During upgrades, there is more than one StatefulSet version for an QuarksStatefulSet resource. The operator lists available versions and keeps track of which are running.\nA running version means that at least one pod that belongs to a StatefulSet is running. When a version n is running, any version lower than n is deleted.\nThe controller continues to reconcile until there’s only one version.\nAZ Support The zones key defines the availability zones the QuarksStatefulSet needs to span.\nThe zoneNodeLabel defines the node label that defines a node’s zone. The default value for zoneNodeLabel is failure-domain.beta.kubernetes.io/zone.\nThe example below defines an QuarksStatefulSet that should be deployed in two availability zones, us-central1-a and us-central1-b.\n1 2 3 4 5 6 7 8 9 10 11 12  apiVersion:quarks.cloudfoundry.org/v1alpha1kind:QuarksStatefulSetmetadata:name:MyQuarksStatefulSetspec:zoneNodeLabel:\"failure-domain.beta.kubernetes.io/zone\"zones:[\"us-central1-a\",\"us-central1-b\"]...template:spec:replicas:2...   The QuarksStatefulSet controller creates one StatefulSet version for each availability zone, and adds affinity information to the pods of those StatefulSets:\n1 2 3 4 5 6 7 8  affinity:nodeAffinity:requiredDuringSchedulingIgnoredDuringExecution:nodeSelectorTerms:-matchExpressions:-key:\"failure-domain.beta.kubernetes.io/zone\"operator:Invalues:[\"us-central1-a\"]   If zones are set for an QuarksStatefulSet, the following occurs:\n The name of each created StatefulSet is generated as \u003cquarks statefulset name\u003e-z\u003cindex of az\u003e.\n1  myquarksstatefulset-z0   The StatefulSet and its Pods are labeled with the following:\n1 2  quarks.cloudfoundry.org/az-index:\"0\"quarks.cloudfoundry.org/az-name:\"us-central1-a\"   The StatefulSet and its Pods are annotated with an ordered JSON array of all the availability zones:\n1  quarks.cloudfoundry.org/zones:'[\"us-central1-a\", \"us-central1-b\"]'   As defined above, each pod is modified to contain affinity rules.\n Each container and init container of each pod have the following env vars set:\n1 2 3 4  KUBE_AZ=\"zone name\" BOSH_AZ=\"zone name\" CF_OPERATOR_AZ=\"zone name\" AZ_INDEX=\"zone index\"    Tolerations Taints and tolerations is a concept defined in kubernetes to repel pods from nodes link. Defining tolerations is same as defined in the kubernetes docs. Keep in mind the affinity rules added by the controller when az’s are defined. An example is specified in the examples folder.\nRestarting on Config Change QuarksStatefulSets can be automatically updated when the environment/mounts have changed due to a referenced ConfigMap or a Secret being updated. This behavior is controlled by the updateOnConfigChange flag which defaults to false.\nWatches in cleanup controller  StatefulSet: Creation/Update  Reconciliation in cleanup controller It will delete statefulsets with old versions, only after the new statefulset version instances are up and running.\nQuarksStatefulSet Active-Passive Controller Fig. 3: The QuarksStatefulset active/passive controller\nActive/passive model is application model that have multiple running instances, but only one instance is active and all other instances are passive (standby). If the active instance is down, one of the passive instances will be promoted to active immediately.\nThe activePassiveProbes key defines active probe to be performed on a container. The controller examines the active probe periodically to see if the active one is still active. If active pod is down or there isn’t an active pod, the first running pod will be promoted as active and label it as quarks.cloudfoundry.org/pod-active: active.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  apiVersion:quarks.cloudfoundry.org/v1alpha1kind:QuarksStatefulSetmetadata:name:myquarksstatefulsetspec:activePassiveProbes:busybox:# define a active probe on the containerexec:command:-/bin/sh--c-/root/check-active.shtemplate:spec:replicas:2template:spec:containers:-name:busyboximage:busyboxcommand:-sleep-\"3600\"...   The controller manages this active probing and provides pod designation label to the service’s selectors. Any requests sent to the service will then only be sent to the active pod.\nRelationship with the BDPL component Fig. 4: Relationship with the BPM controller\nFigure 4 illustrates the interaction of the BPM Controller with the QuarksStatefulSet Controller. Once the BPM controller consumes the data persisted in secrets from the QuarksJob Component, it will use that data to generate new QuarksStatefulset instances. When these resources are generated, the QuarksStatefulSet controller will be watching and trigger its reconciliation loop.\nQuarksStatefulSet Examples See https://github.com/cloudfoundry-incubator/cf-operator/tree/master/docs/examples/quarks-statefulset\n","excerpt":"  QuarksStatefulSet  Description QuarksStatefulSet Component …","ref":"/docs/development/controllers/quarks_statefulset/","title":"Quarks StatefulSet"},{"body":" Motivation The former implementation use a new StatefulSet for each new version of a manifest. This had the following drawbacks:\n Update on a cluster with multiple nodes was not working. When the new pods were started on a different node, the volume was blocked by the old pod. On a single node cluster this was also not working, if the workload (e.g. mysql) was using a lock on the volume on file-system level.  Why standard K8s StatefulSet is not sufficient  Out-of-order updates are possible when e.g. a pod/node crashes. Recovering from a failed deployment is not possible with the standard kubernetes StatefulSet controller. There is no timeout when the new deployment is rolled out and is stuck.  Statemachine This controller implements the following state machine\nKnown Limitations CanaryUpscale During upscale, there is no real canary behaviour implemented. If a StatefulSet is scaled from 3 to 5 replicas, the state changes to CanaryUpscale and Partition is set to 2. The k8s statefulset controller creates the 2 missing instances. If all instances are ready the controller switches to state Rollout and continues as usual. Due to the fact that more than 1 instance might be updated in state CanaryUpscale, the update-watch-time is used as timeout.\nSingle Replica The former implementation was starting a second pod during the update before shutting down the old one. This is no longer possible as the name of the pod won’t change and results in a downtime.\n","excerpt":" Motivation The former implementation use a new StatefulSet for each …","ref":"/docs/development/controllers/statefulsetrollout/","title":"StatefulSet Rollout"},{"body":" There might be situations where things might go wrong, this section is providing tips to debug issues in your cluster and your applications deployed with quarks-operator.\nYou should also check the known issues for the release you are using.\nAlso, checkout these awesome tools that can help you while debugging your cluster.\nKubernetes events The quarks-operator streams results of its actions throughout logs and Kubernetes events. If you notice issues, or if you are just unsure on what is happening, check first the event logs of all the namespaces (or the namespace where you are deploying your bosh release)\n1  $\u003e kubectl get events -A   Checking logs Catching logs from all the quarks-operator components might be somehow challenging, we suggest to use stern.\nFor example, to stream all the logs of all pods in your cluster in your terminal:\n1  $\u003e stern --all-namespaces .   With kubectl, you can check all container logs with:\n1  $\u003e kubectl logs -n namespace -f pod --all-containers   Debugging BOSH Releases The quarks operator exposes a debug parameter to enable hooking into a bosh release before starting. In this way you can open a shell in a pod for further debugging. To do so, you have to specify quarks.debug=true to the relevant part you are interested in debugging, for example, in your Configmap:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  ---apiVersion:v1kind:ConfigMapmetadata:name:quarks-gora-manifestdata:manifest:| ---name:quarks-gora-deploymentreleases:-name:quarks-gora....instance_groups:-name:quarks-gorajobs:-name:quarks-gorarelease:quarks-goraproperties:quarks:debug:true   Checking containers state We strongly suggest to use k9s. It gives a quick glance over your cluster state, and quickly allows to introspect pods container statuses.\nIn most cases, while you are debugging a BOSH deployment you will have to check the states of all the containers running in a pod.\nYou can do that in k9s by navigating into the pod and pressing [Enter] , in plain kubectl commands, you can describe a resource to get all its events and in case of pods, an overview of all the containers belonging to it\n1  $\u003e kubectl describe pod my-bosh-release   or, if you are checking a QuarksSecret state:\n1  $\u003e kubectl describe qsec my-quarks-secret   My pod looks stuck There might be various reasons why this could happen, here are few suggestions:\n Check if your pod is having a container with the wait-for prefix, means it’s waiting for a specific service which can be identified by the container name. Check if your pod is depending on a secret which isn’t being generated yet. If the secret is generated by a QuarksSecret, check the events related to the QuarksSecret which should generate it (with kubectl describe ..., or kubectl events).  Cluster CA The cf-operator assumes that the cluster root CA is also used for signing CSRs via the certificates.k8s.io API and will embed this CA in the generated certificate secrets. If your cluster is set up to use a different cluster-signing CA the generated certificates will have the wrong CA embedded. See https://kubernetes.io/docs/tasks/tls/managing-tls-in-a-cluster/ for more information on cluster trust.\nRecovering from a crash If the operator pod crashes from unrecoverable errors, it cannot be restarted in the same namespace before the existing mutating webhook configuration for that namespace is removed. The operator uses mutating webhooks to modify pods on the fly and Kubernetes fails to create pods if the webhook server is unreachable. The webhook configurations are installed cluster wide and don’t belong to a single namespace, just like custom resources.\nTo remove the webhook configurations for the cf-operator namespace run:\n1 2 3  CF_OPERATOR_NAMESPACE=cf-operator kubectl delete mutatingwebhookconfiguration \"cf-operator-hook-$CF_OPERATOR_NAMESPACE\" kubectl delete validatingwebhookconfiguration \"cf-operator-hook-$CF_OPERATOR_NAMESPACE\"   From Kubernetes 1.15 onwards, it is possible to instead patch the webhook configurations for the cf-operator namespace via:\n1 2 3 4 5 6 7 8 9 10 11  CF_OPERATOR_NAMESPACE=cf-operator kubectl patch mutatingwebhookconfigurations \"cf-operator-hook-$CF_OPERATOR_NAMESPACE\" -p ' webhooks: - name: mutate-pods.quarks.cloudfoundry.org objectSelector: matchExpressions: - key: name operator: NotIn values: - \"cf-operator\" '   See also how to monitor admission webhooks if you are debugging the changes introduced by a Quarks operator webhook\n","excerpt":" There might be situations where things might go wrong, this section …","ref":"/docs/core-tasks/troubleshooting/","title":"Troubleshooting"},{"body":" The following is a list of tools with their respective main features that can help you to simplify your development work when dealing with quarks-operator and kubecf\nk9s k9s provides an easy way to navigate through your k8s resources, while watching lively to changes on them. Main features that can be helpful for containerized CF are:\n inmediate access to resources YAMLs definition\n inmediate access to services endpoints\n inmediate access to pods/container logs\n sort resources(e.g. pods) by cpu or memory consumption\n inmediate access to a container secure shell\n  havener havener is a tool-kit with different features around k8s and CloudFoundry\n top, to get an overview on the cpu/memory/load of the cluster, per ns and pods.\n logs, to download all logs from all pods into your local system\n pod-exec, to open a shell into containers. This can execute cmds in different containers simultaneously.\n node-exec, to open a shell into nodes. This can execute cmds in different containers simultaneously.\n  stern stern allows you to tail from your terminal to multiple pod logs on Kubernetes, including all containers.\nkube dashboard kube dashboard is a more user friendly way to navigate your k8s cluster resources.\n","excerpt":" The following is a list of tools with their respective main features …","ref":"/docs/development/tooling/","title":"Nice tools to use"},{"body":" The intended audience of this document are developers wishing to contribute to the Quarks project.\nIt provides a basic overview of various aspects of the project below, and uses these overviews as the launching points to other documents which go deeper into the details of each aspect.\n Contributing to CF-Operator First, thanks for taking the time to contribute to the project!\nThe following is a set of guidelines for contributing to CF-Operator. Use your best judgment, and feel free to propose changes to this document in a pull request.\nHow to contribute Please do not report security vulnerabilities in public issues!\nInstead, report to the CloudFoundry Foundation team first security@cloudfoundry.org and give us some time to fix it in a timely matter before disclosing it to the public. For more information check the CloudFoundry Security page.\nDon’t forget to familiarize yourself with our processes and tools, by reading about them here.\nConversation When contributing to this repository, please discuss the changes through an existing Github issue with the core team. We believe it’s the right place to have an open conversation.\nPull Request Pull Requests are the most well-known way to contribute to any project and they are more than welcome in the CF-Operator project. Commit messages must be clear and concise to help the reviewer understand what the PR is doing.\nIssues tracker The CF-Operator workload is tracked here. All Github issues are synced with this tracker, so all community issues (either bugs or features) should go to Github.\nWe want short and accurate templates for different types of issues, to gather required information and to start a conversation. Once again, feel free to improve them by opening a pull request.\nHow to report a bug Start by searching [bugs][1] for some similar issues and/or extra information. If your search doesn’t bring you any help then open an issue by selecting the issue type “Bug” and fill the template as accurately as possible.\nHow to suggest a feature/enhancement If you find yourself wishing for a feature/enhancement that doesn’y exist yet in CF-Operator, start by running a quick [search][2] - you may not be alone! If you’re out of luck, then go ahead and open a new issue by selecting the “Feature” issue type and answer some needed questions.\nHow are Github issues handled When you create a github issue, cf-bot creates a story in the IceBox board in the tracker automatically and comments on the issue with the link to the story. The core team conducts its planning session once every week during which your issue will be discussed.\n If the story is moved to the Current Iteration/Backlog board, then expect that the story would be worked on in the coming sprints. If the story is left out in the IceBox board itself, then expect that the story low in priority. If the github issue becomes stale, it might be closed even though we plan to work on it. The core team will reopen it when work begins. Both the github issue and the story will be closed if there is no response for more than 30 days when contacted.  How are tracker stories handled  By default, a story is in an Unstarted state. When the developer clicks on the Start button, the story moves to Started state. When the developer finishes the story, submits a PR and clicks on Finish button, the story moves to Finished state. After approving all PRs that belong to a story, the reviewer and author then try to merge and rebase those PRs, changing references as needed, and ensure all tests are still green. Finally one of them clicks the Deliver button which is when the story moves to the Delivered state. The team lead, after checking the feature/bugfix, will accept the story. That is the end of the life of a story. A detailed flow diagram can be found here.  Code review process The core team looks to Pull Requests regularly and in a best effort.\nCommunity You can chat with the core team on the Slack channel #quarks-dev, on the Cloud Foundry Slack.\nCode of conduct Please refer to Code of Conduct\nLinks  Bugs Features Readme  ","excerpt":" The intended audience of this document are developers wishing to …","ref":"/docs/contribution-guidelines/","title":"Contribution Guidelines"},{"body":"","excerpt":"","ref":"/docs/core-tasks/","title":"Core tasks"},{"body":"A desired manifest is a BOSH deployment manifest that has already been calculated so that it’s the actual final state that the user wishes his software to be in. All ops files have been applied, variables have been calculated and replaced. This manifest is persisted and versioned.\nOps files are applied by the operator. Variables are replaced by an QuarksJob that runs the operator’s image. The QuarksJob writes the manifest on stdout, which is persisted using a Versioned Secret.\nEach manifest version that goes live is immutable. A manifest’s version is an integer that gets incremented. The current version of the manifest is the greatest version.\nThese manifests are kept in secrets named using the following rule:\n1  \u003coperator-namespace\u003e/\u003cdeployment-name\u003e.desired-manifest-v\u003cversion\u003e    deployment-name: the name of deployment manifest version: the version of manifest  Each secret is also annotated and labeled with information such as:\n the deployment name the secret kind its version a description of the “sources” used to render the manifest (e.g. the location of the CRD that generated it).  ","excerpt":"A desired manifest is a BOSH deployment manifest that has already been …","ref":"/docs/features/desired_manifests/","title":"Desired Manifests"},{"body":"","excerpt":"","ref":"/docs/development/","title":"Development"},{"body":" Also known as “Quarks Links” - they provide a way to share/discover information between BOSH and Kube Native components.\nUsing k8s Native Values in BOSH Deployments (Native -\u003e BOSH) In this case, the native component is a provider, and the BOSH component is a consumer.\nWe construct link information from the native resources like this:\n   BOSH Link Native Description     address Service DNS address of a k8s service annotated quarks.cloudfoundry.org/provides = LINK_NAME   azs N/A not supported   properties  properties retrieved from a secret annotated quarks.cloudfoundry.org/provides = LINK_NAME   instances.name Pod name of pod selected by the k8s service that’s annotated quarks.cloudfoundry.org/provides = LINK_NAME   instances.id Pod pod uid   instances.index Pod set to a value 0-(pod replica count)   instances.az N/A not supported   instances.address Pod ip of pod   instances.bootstrap Pod set to true if index == 0     If multiple secrets or services are found with the same link information, the operator should error\n Example (Native -\u003e BOSH) When a job consumes a link, it will have a section like this in the in its job spec (job.MF), e.g. the nats release:\n1 2 3  consumes:-name:natstype:nats   We can create the following k8s secret to fulfill the link:\n1 2 3 4 5 6 7 8 9 10 11 12  kind:Secretmetadata:name:secretlinklabels:quarks.cloudfoundry.org/deployment-name:\"mydeployment\"annotations:quarks.cloudfoundry.org/provides:'{\"name\":\"nats\",\"type\":\"nats\"}'spec:data:link:| nats.user: myusernats.password:mysecret   Using this secret, the nats release can use link(\"nats\").p(\"password\") in its eruby templates.\n1  \"\u003c%= p(\"nats.password\") %\u003e\"   Furthermore, if there is a matching k8s service, it will be used in the link:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  apiVersion:v1kind:Servicemetadata:labels:quarks.cloudfoundry.org/deployment-name:\"mydeployment\"annotations:quarks.cloudfoundry.org/link-provider-name:natsname:nats-servicespec:ports:-port:9099protocol:TCPtargetPort:9099selector:app:mynats   Using this service, I should be able to use link(\"nats\").address, and I should get a value of nats-service.\nThis service selects for Pods that have the label app: mynats. The instances array should be populated using information from these pods.\nIf the secret is changed, consumers of the link are automatically restarted.\nIf the service is changed, or the list of pods selected by the service is changed, consumers of the link are automatically restarted.\nUsing BOSH Variables in k8s Pods (BOSH -\u003e Native) In this case, the BOSH component is a provider, and the native component is a consumer. The native component is pod, which might belong to a deployment or statefulset.\nThe operator creates link secrets for all providers in a BOSH deployment. Each secret contains a flattened map with the provided properties:\n1 2 3 4 5 6 7 8 9 10 11 12  apiVersion:v1kind:Secretmetadata:name:link-test-nats-natsannotations:quarks.cloudfoundry.org/restart-on-update:\"true\"labels:quarks.cloudfoundry.org/entanglement:link-test-nats-natsdata:nats.password:YXBwYXJlbnRseSwgeW91Cg==nats.port:aGF2ZSB0b28Knats.user:bXVjaCB0aW1lCg==   If a pod is annotated with the following:\n quarks.cloudfoundry.org/deployment: foo quarks.cloudfoundry.org/consumes: '[{\"name\":\"nats\",\"type\":\"nats\"}]'  The operator will mutate the pod to:\n mount the link secrets as /quarks/link/DEPLOYMENT/\u003ctype\u003e-\u003cname\u003e/\u003ckey\u003e add an environment variable for each key in the secret data mapping: LINK_\u003ckey\u003e  The \u003cname\u003e and \u003ctype\u003e are the respective link type and name. For example, the nats release uses nats for both the name and the type of the link. The \u003ckey\u003e describes the BOSH property, flattened (dot-style), for example nats.password. The key name is modified to be upper case and without dots in the context of an environment variable, therefore nats.password becomes LINK_NATS_PASSWORD in the container.\nIf link information changes, the operator will trigger an update (restart) of the deployment or statefulset owning the pod. This can be done by updating the template of the pod using an annotation.\nExample (BOSH -\u003e Native) an Eirini Helm Chart\nThe OPI process of Eirini required the NATS password and IP.\n1 2 3 4 5 6  ...template:metadata:quarks.cloudfoundry.org/deployment:{{.Values.deploymentName}}quarks.cloudfoundry.org/consumes:'[{\"name\":\"nats\",\"type\":\"nats\"}]'`spec:   and a CF-Deployment with Operator, which has the following instance groups: - API - Diego Cell - Gorouter - NATS provides: nats\n","excerpt":" Also known as “Quarks Links” - they provide a way to share/discover …","ref":"/docs/features/entanglements/","title":"Entanglements"},{"body":" Quarks-operator deploys dockerized BOSH releases onto existing Kubernetes cluster\n Supports operations files to modify manifest Service instance groups become pods, each job in one container Errand instance groups become QuarksJobs  To do this it relies on three Kubernetes components:\n QuarksSecret, a custom resource and controller for the generation and rotation of secrets QuarksJob, templating for Kubernetes jobs, which can trigger jobs on configuration changes and persist their output to secrets QuarksStatefulSet, adds canary, zero-downtime deployment, zones and active-passive probe support QuarksRestart, restarts statefulset and deployment if the referenced secret changes  The Quarks-operator supports RBAC and uses immutable, versioned secrets internally.\nCompatibility with BOSH  Supports BOSH deployment manifests, including links and addons Uses available BPM information from job releases Renders ERB job templates in an init container, before starting the dockerized BOSH release Adds endpoints and services for instance groups BOSH DNS support Uses Kubernetes zones for BOSH AZs Interaction with configuration:\n BOSH links can be provided by existing Kubernetes secrets Provides BOSH link properties as Kubernetes secrets Generates explicit variables, e.g. password, certificate, and SSH keys Reads implicit variables from secrets Secret rotation for individual secrets  Adapting releases:\n Pre-render scripts to patch releases, which are incompatible with Kubernetes  Lifecycle related:\n Restart only affected instance groups on update Sequential startup of instance groups Kubernetes healthchecks instead of monit   ","excerpt":" Quarks-operator deploys dockerized BOSH releases onto existing …","ref":"/docs/features/","title":"Features"},{"body":"  Naming Conventions  Kubernetes Resources Kubernetes Services   Kubernetes Resources Kube names can only consist of lowercase alphanumeric characters, and the character \"-\". All \"_\" characters are replaced with \"-\". All other non-alphanumeric characters are removed.\nThe name cannot start or end with a \"-\". These characters are trimmed.\nNames are also restricted to 63 characters in length, so if a generated name exceeds 63 characters, it should be recalculated as:\n1 2 3  name=\u003cINSTANCE_GROUP_NAME\u003e-\u003cINDEX\u003e\u003cDEPLOYMENT_NAME\u003e \u003cname trimmed to 31 characters\u003e\u003cmd5 hash of name\u003e   Kubernetes Services The same check needs to apply to the entire address of a Service. If an entire address is longer than 253 characters, the servicename is trimmed until there’s enough room for the MD5 hash. If it’s not possible to include the hash (KUBE_NAMESPACE and KUBE_SERVICE_DOMAIN and the dots are 221 characters or more), an error is thrown.\n","excerpt":"  Naming Conventions  Kubernetes Resources Kubernetes Services …","ref":"/docs/concepts/naming/","title":"Naming Conventions"},{"body":" Background \u0026 Motivation Before kubecf the processes of the jobs in an instance group were managed by monit.\nThis allowed a human operator to suspend (kill) and later restart these processes as a means of preventing them from interfering with low-level operations like restoring a cluster using raw database backups, and the like. Such suspensions were also not visible at kube level as the pod and container kept running, except through live- and readiness-probes.\nThe process control features added to the containerun helper application of the operator serve the same purpose.\nInterface The process control features of containerrun are accessible through an unix domain datagram socket at location /var/vcap/data/JOB/PROCESS_containerrun.sock in the container. Due to this placement the feature is not accessible from outside a cluster. An operator (or script written by such) has to log into the relevant container(s) to use the feature.\n Suspending the monitored child processes is done by sending the command STOP to this socket.\n Conversely, restarting the child processes is done by sending the command START to this socket.\n Sending a START command when the child processes are running has no effect. Conversely the same is true for sending a STOP command when the child processes are suspended already.\n Any other command sent to the socket is ignored.\n  Any tool able to send datagram packet to a unix domain socket of that type should work.\nExamples using netcat:\n echo START | nc -w 1 --unixsock --udp /var/vcap/data/JOB/PROCESS_containerrun.sock echo STOP | nc -w 1 --unixsock --udp /var/vcap/data/JOB/PROCESS_containerrun.sock  Note that all of these sockets are placed in the volumne shared by all container of all jobs of the instance group. It is enough to ssh into one of the containers to be able to send commands to all sockets and thus jobs.\nExample:\nfor sock in $(find /var/vcap/dataame '*_containerrun.sock') do echo STOP | nc -w 1 --unixsock --udp $sock done  ","excerpt":" Background \u0026 Motivation Before kubecf the processes of the jobs in an …","ref":"/docs/features/process_control/","title":"Process Control"},{"body":"  QuarksJob  Description Features Errand Jobs One-Off Jobs / Auto-Errands  Restarting on Config Change  Persisted Output  Versioned Secrets  QuarksJob Examples   Description A QuarksJob allows the developer to run jobs when something interesting happens. It also allows the developer to store the output of the job into a Secret. The job started by an QuarksJob is deleted automatically after it succeeds.\nThere are two different kinds of QuarksJob:\n one-offs: automatically runs once after it’s created errands: needs to be run manually by a user  Features Errand Jobs Errands are run manually by the user. They are created by setting trigger.strategy: manual.\nAfter the QuarksJob is created, run an errand by editing and applying the manifest, i.e. via kubectl edit errand1 and change trigger.strategy: manual to trigger.strategy: now. A kubectl patch is also a good way to trigger this type of QuarksJob.\nAfter completion, this value is reset to manual.\nLook here for a full example of an errand.\nOne-Off Jobs / Auto-Errands One-off jobs run directly when created, just like native k8s jobs.\nThey are created with trigger.strategy: once and switch to done when finished.\nIf a versioned secret is referenced in the pod spec of an qJob, the most recent version of that secret will be used when the batchv1.Job is created.\nRestarting on Config Change A one-off QuarksJob can automatically be restarted if its environment/mounts have changed, due to a ConfigMap or a Secret being updated. This also works for Versioned Secrets.\nThis requires the attribute updateOnConfigChange to be set to true.\nOnce updateOnConfigChange is enabled, modifying the data of any ConfigMap or Secret referenced by the template section of the job will trigger the job again.\nPersisted Output QuarksJob can create secrets from job output, which is written to a JSON file in /mnt/quarks.\nMultiple secrets are created or overwritten per container in the pod. The output file names are mapped to the secrets’ names via OutputMap. This is done for every container.\nThe only supported output type currently is json with a flat structure, i.e. all values being string values, because Kubernetes secrets store base64 encoded data. The string value can be a marshalled JSON document.\nNote: Output of previous runs is overwritten.\nThe behavior of storing the output is controlled by specifying the following parameters:\n outputMap - Mapping from output file name to the name of the secret(s) that will hold the output. outputType - Currently only json is supported. (default: json) secretLabels - An optional map of labels which will be attached to the generated secret(s) writeOnFailure - if true, output is written even though the Job failed. (default: false)  The developer should ensure that she creates all files defined in OutputMap in the /mnt/quarks volume mount at the end of the container script. An example of the command field in the quarks job spec will look like this\ncommand: [\"/bin/sh\"] args: [\"-c\",\"json='{\\\"foo\\\": \\\"1\\\", \\\"bar\\\": \\\"baz\\\"}' \u0026\u0026 echo $json \u003e\u003e /mnt/quarks/output.json\"]  The secret is created by a side container in quarks job pod which captures the create event of /mnt/quarks/output.json file.\nThe behavior of storing the output is controlled by specifying the following parameters:\n outputType - Currently only json is supported. (default: json) secretLabels - An optional map of labels which will be attached to the generated secret(s) versioned - if true, the output is written in a Versioned Secret writeOnFailure - if true, output is written even though the Job failed. (default: false)  Versioned Secrets Versioned Secrets are a set of Secrets, where each of them is immutable, and contains data for one iteration. Implementation can be found in the versionedsecretstore package.\nWhen an QuarksJob is configured to save to “Versioned Secrets”, the controller looks for the Secret with the largest ordinal, adds 1 to that value, and creates a new Secret.\nEach versioned secret has the following characteristics:\n its name is calculated like this: \u003cname\u003e-v\u003cORDINAL\u003e e.g. mysecret-v2 it has the following labels:  quarks.cloudfoundry.org/secret-kind with a value of versionedSecret quarks.cloudfoundry.org/secret-version with a value set to the ordinal of the secret  an annotation of quarks.cloudfoundry.org/source-description that contains arbitrary information about the creator of the secret  QuarksJob Examples See https://github.com/cloudfoundry-incubator/quarks-job/tree/master/docs/examples\nController architecture See: Quarks Job controller section\n","excerpt":"  QuarksJob  Description Features Errand Jobs One-Off Jobs / …","ref":"/docs/components/quarksjob/","title":"Quarks Job"},{"body":"  Rendering BOSH Templates  Flow Data Gathering  Extract Job Spec and Templates from Image Calculation of Required Properties for an Instance Group and BPM Info  Run  Create QuarksStatefulSet and QuarksJobs Render Templates Run the entrypoints  Details Services and DNS Addresses Resolving Links Calculating spec.* and link().instances[].* FAQ   You can read more about BOSH templates on bosh.io.\nFlow The following points describe each process that involves working with BOSH Job Templates, from beginning to end.\nData Gathering The Data Gathering step is run using one QuarksJob, that has one pod with multiple containers.\nExtract Job Spec and Templates from Image This happens in one init container for each release present in the deployment manifest.\nThe entrypoint of that init container is responsible with copying the contents of /var/vcap/jobs-src to a shared directory, where other containers can access it. This shared directory is /var/vcap/all-releases/jobs-src.\nEach init container uses the release’s docker image.\nCalculation of Required Properties for an Instance Group and BPM Info The main purpose of the data gathering phase is to compile all information required for all templates to be rendered and for all instance groups to be run:\n properties link instances bpm yaml  Two containers are run for each instance group in the deployment manifest, using the image of the CF Operator. These two containers write the following on to a file output.json in the volume mount /mnt/quarks of the container :\n A Secret named ig-resolved.\u003cinstance-group\u003e-v\u003cversion\u003e\nThis is the “Resolved Instance Group Properties” yaml file. It contains a deployment manifest structure that only has information pertinent to an instance group. It includes:\n all job properties for that instance group all properties for all jobs that are link providers to any of the jobs of that instance group the rendered contents of each bpm.yml.erb, for each job in the instance group link instance specs for all AZs and replicas; read more about instance keys available for links here   Note:\nLink instance specs are stored in the quarks property key for each job in the instance group.\n a Secret named bpm.\u003cinstance-group\u003e-v\u003cversion\u003e\nOnce all properties and link instances are compiled, bpm.yml.erb can be rendered for each job and for each AZ and replica of the instance group.\nThe output of this container is the “BPM Info” yaml file. It contains a deployment manifest structure that only has information pertinent to an instance group. It includes the rendered contents of each bpm.yml.erb, for each job in the instance group.\n Note:\nThe BPM information is stored under the quarks property, for each BOSH Job.\nImportant:\nBecause container entrypoints in Kubernetes cannot be different among the replicas of a Pod, we don’t support the usage of things like spec.index in the ERB template of bpm.yaml.\n  Run Create QuarksStatefulSet and QuarksJobs The operator creates definitions for QuarksStatefulSets (for BOSH Services) or QuarksJobs (for BOSH Errands).\nThese have the following init containers:\n one for each unique release in the instance group - used for copying release job specs and templates; these use the release image\n one init container that performs ERB rendering; this runs using the CF Operator image\n  Render Templates Init containers copy the templates of the releases to /var/vcap/all-releases, which is a shared directory among all containers.\nAnother init container is run using the operator’s image, for rendering all templates. It mounts the “Resolved Instance Group Properties” Secret (generated in the data gathering step) and performs ERB rendering. It’s also configured with the following environment variables, to facilitate BOSH spec.* property keys:\n INSTANCE_GROUP_NAME AZ_INDEX REPLICAS  Run the entrypoints Once all the init containers are done, all control scripts and configuration files are available on disk, the BOSH Job containers can start. Their entrypoints, env vars, capabilities, etc. are set based on BPM information.\nDetails The following section describes specific implementation details for algorithms required in the rendering process.\nServices and DNS Addresses DNS Addresses for instance groups are calculated in the following manner:\n1  \u003cDEPLOYMENT_NAME\u003e-\u003cINSTANCE_GROUP_NAME\u003e-\u003cINDEX\u003e.\u003cKUBE_NAMESPACE\u003e.\u003cKUBE_SERVICE_DOMAIN\u003e   The INDEX is calculated using the following formula:\n1  (AZ_INDEX - 1) * REPLICAS + POD_ORDINAL   In order for things to work correctly across versions and AZs, we need ClusterIP Services that select for Instance Group Pods.\nFor example, assuming a REPLICAS of 3 and an AZ_COUNT of 2 for a “nats” BOSHDeployment, with 2 StatefulSet versions available, we would see the following Services:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  nats-0 selects pod z0-v1-0 selects pod z0-v2-0 nats-1 selects pod z1-v1-0 selects pod z1-v2-0 nats-2 selects pod z0-v1-1 selects pod z0-v2-1 nats-3 selects pod z1-v1-1 selects pod z1-v2-1 nats-4 selects pod z0-v1-2 selects pod z0-v2-2 nats-5 selects pod z1-v1-2 selects pod z1-v2-2   Resolving Links The following steps describe how to resolve links assuming all information is available. The actual implementation transforms data and stores it in between steps, but the outcome is the same.\nTo resolve a link, the following steps are performed:\n Vocabulary:\n current job - the job for which rendering is happening desired manifest - the deployment manifest used provider job - the job that has been identified to be the provider for a link    the name and type of the link is retrieved from the spec of the current job the name of the link is looked up in the current job’s instance group consumes key (an explicit link definition); if found and is set to nil, nil is returned and resolving is complete if the link’s name has been overridden by an explicit link definition in the desired manifest, the desired manifest is searched for a corresponding job, that has the same name; if found, the link is populated with the properties of the provider job; first, the defaults for the exposed properties (defined in the provides section of the spec of the provider job) are set to the defaults from the spec, and then the properties from the desired manifest are applied on top if there was no explicit override, we search for a job in all the releases, that provides a link with the same type   Read more about links here.\n Calculating spec.* and link().instances[].* The spec of each job instance can be calculated:\n1 2 3 4 5 6  name:\u003cnameoftheinstancegroup\u003e-\u003cnameofthejob\u003eindex:(\u003cazindex\u003e-1)*\u003creplicas\u003e+\u003cpod_ordinal\u003eaz:\u003cBOSH_AZ_INDEX\u003eid:\u003cnameoftheinstancegroup\u003e-\u003cindex\u003e-\u003cnameofthejob\u003eaddress:\u003ccalculatedaddress\u003ebootstrap:\u003cindex==0\u003e   FAQ  Why render BPM separately from all other BOSH Job Templates?  Because we need information from BPM to actually know what to run. Without that, we don’t have an entrypoint, env vars, etc. - so we can’t create a pod and containers for the BOSH Job.\n Why run all release images for Data Gathering?  We need to run everything all at once because of links. The only way to resolve them is to have all the BOSH Job specs available in one spot.\n Is everything supported in templates, just like BOSH?  It should, yes. All features should work the same (that’s the goal).\n Known Exceptions:\n The use of spec.ip in bpm.yml.erb  Since bpm.yml is rendered before the actual instance group runs, in a different pod, spec.ip is invalid.\n The use of spec.index in bpm.yml.erb  Any BPM information that is different for each replica, cannot be supported by the CF Operator, because all Pod replicas are identical by definition.\n ","excerpt":"  Rendering BOSH Templates  Flow Data Gathering  Extract Job Spec and …","ref":"/docs/features/rendering_templates/","title":"Rendering BOSH Templates"},{"body":"To support clean deployments and correct depedency management, the quarks-operator allows a Kubernetes Pod to wait until one (or more) Service is available.\nThe operator does that by injecting an InitContainer which waits for the service to be up.\nThis is a generalization of the serialization hints natively available to all BOSH deployments.\nThe Pods needs to have the quarks.cloudfoundry.org/wait-for annotation, for example:\n1 2 3 4 5  apiVersion:v1kind:Podmetadata:annotations:quarks.cloudfoundry.org/wait-for:'[ \"nats-headless\" , \"nginx\" ]'   At the ops level this is achieved by an instruction like\n1 2 3  -type:replacepath:/instance_groups/name=THE_INSTANCE_GROUP/env?/bosh/agent/settings/annotations/quarks.cloudfoundry.org~1wait-forvalue:'[ \"uaa\" ]'    The env/bosh/agent/settings/annotations key is a hash used by the operator to add additional annotations to the k8s objects it creates for an instance group. IOW they are applied to the generated quarks-statefulset, statefulset, and pod.  :warning: Note that while the dependency information is ultimately processed as a json array of strings, at the level of the annotations it has to be specified as a plain string. Just one which contains proper json syntax.\nIf full custom dependencies are not required, just (partial) serial startup of instance groups (in the order of their specification in their deployment) then the native serialization hints are likely good enough.\nThey are specified via a construction of the form\n1 2 3 4  instance_groups:-name:THE_INSTANCE_GROUPupdate:serial:true   in the BOSH deployment, if under direct control, or via an ops file like\n1 2 3  -type:replacepath:/instance_groups/name=THE_INSTANCE_GROUP/update/serialvalue:true   if the deployment cannot be modified directly.\n","excerpt":"To support clean deployments and correct depedency management, the …","ref":"/docs/features/waiting_services/","title":"Service wait for Kubernetes native pods"},{"body":"The quarks-operator is composed by different stand-alone controllers that can be deployed separately.\n","excerpt":"The quarks-operator is composed by different stand-alone controllers …","ref":"/docs/components/","title":"Components"},{"body":" Description A QuarksSecret lets you automatically generate secrets such as passwords, certificates and ssh keys, to ease management of credentials in Kubernetes.\nOverview of Quarks Secret A QuarkSecret is a Kubernetes Object that contains instuctions on the type of Kubernetes Secret that must be generated which can be later referenced in a Pod.\nFor instance, to generate a basic auth password, we can apply the following yaml with kubectl:\n 1 2 3 4 5 6 7  apiVersion:quarks.cloudfoundry.org/v1alpha1kind:QuarksSecretmetadata:name:generate-passwordspec:type:passwordsecretName:gen-secret1    Complete source code: https://github.com/cloudfoundry-incubator/quarks-secret/blob/master/docs/examples/password.yaml   the type field denotes the type of secret that should be generated, currently quarks-secret supports the following types:\n password certificate ssh rsa basic-auth dockerconfigjson copy  Generate credentials QuarksSecret can be used to generate passwords, certificates and keys. It uses the cfssl package to generate these. The generated values are stored in kubernetes secrets.\nRotate credentials The generated credentials can be rotated by specifying its quarkssecret’s name in a configmap. The configmap must have the following label:\nquarks.cloudfoundry.org/secret-rotation  Approve Certificates In the case, where a certificate is generated, the QuarksSecret ensures that a certificate signing request is generated and is approved by the Kubernetes API server.\nSecret copy The Quarks Secret operator can generate also copies in multiple namespaces while generating secrets.\nFor example, while generating passwords:\n 1 2 3 4 5 6 7 8 9 10 11  ---apiVersion:quarks.cloudfoundry.org/v1alpha1kind:QuarksSecretmetadata:name:copy-userspec:type:passwordsecretName:gen-secretcopies:-name:copied-secretnamespace:COPYNAMESPACE    Complete source code: https://github.com/cloudfoundry-incubator/quarks-secret/blob/master/docs/examples/copy.yaml   It can be specified a list of copying target, with copies:\n1 2 3  copies:-name:copied-secretnamespace:namespace1   And each destination which is indicated needs to have a Quarks Secret of copy in the following form:\n 1 2 3 4 5 6 7 8 9 10 11 12 13  ---apiVersion:quarks.cloudfoundry.org/v1alpha1kind:QuarksSecretmetadata:labels:quarks.cloudfoundry.org/secret-kind:generatedannotations:quarks.cloudfoundry.org/secret-copy-of:NAMESPACE/copy-username:copied-secretnamespace:COPYNAMESPACEspec:type:copysecretName:copied-secret    Complete source code: https://github.com/cloudfoundry-incubator/quarks-secret/blob/master/docs/examples/copy-qsecret-destination.yaml   The examples copies the generated gen-secret secret content into copied-secret inside the COPYNAMESPACE namespace.\nSee also  Examples Quarks Secret Controller architecture  ","excerpt":" Description A QuarksSecret lets you automatically generate secrets …","ref":"/docs/components/quarkssecret/","title":"Quarks Secret"},{"body":" Incubation Proposal: Containerizing Cloud Foundry Backlog: Pivotal Tracker Docker: https://hub.docker.com/r/cfcontainerization/cf-operator/tags  ","excerpt":" Incubation Proposal: Containerizing Cloud Foundry Backlog: Pivotal …","ref":"/docs/","title":"Documentation"},{"body":"","excerpt":"","ref":"/docs/commands/","title":"Quarks CLI Options"},{"body":"","excerpt":"","ref":"/docs/commands/quarks-job/","title":"Quarks Job"},{"body":"","excerpt":"","ref":"/docs/commands/quarks-secret/","title":"Quarks Secret"},{"body":"","excerpt":"","ref":"/docs/commands/cf-operator/","title":"Quarks-operator"},{"body":" Kubernetes Controllers This folder contains design documents for the Kubernetes controllers that make up the cf-operator.\nAdditional Resources Draw.io with the sources for the quarks_deployment_flow-*png controller charts:\n https://drive.google.com/file/d/1Uk2h5pOmY-gLtbfpDNO3POTcqI5UdZgj/view?usp=sharing  ","excerpt":" Kubernetes Controllers This folder contains design documents for the …","ref":"/docs/development/controllers/readme/","title":""},{"body":"","excerpt":"","ref":"/community/","title":"Community"},{"body":"  #td-cover-block-0 { background-image: url(/featured-background_hu32fcfd66753899134ea529df65124b12_28764_960x540_fill_q75_catmullrom_top.jpg); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/featured-background_hu32fcfd66753899134ea529df65124b12_28764_1920x1080_fill_q75_catmullrom_top.jpg); } }  Quarks project documentation Learn More   Download   Quarks enables the deployment of BOSH Releases, especially Cloud Foundry, to Kubernetes.\n         Quarks-operator enables the deployment of BOSH Releases, especially Cloud Foundry, to Kubernetes.\nIt’s implemented as a k8s operator, an active controller component which acts upon custom k8s resources.\n      BOSH to Kubernetes! Quarks deploys dockerized BOSH releases onto existing Kubernetes cluster\n Supports operations files to modify manifest Service instance groups become pods, each job in one container Errand instance groups become QuarksJobs     Contributions welcome! We do a Pull Request contributions workflow on GitHub. New users are always welcome!\nRead more …\n   Get in touch on Slack! For discussions, announcements, etc.\nRead more …\n    ","excerpt":"  #td-cover-block-0 { background-image: …","ref":"/","title":"Project Quarks"},{"body":"","excerpt":"","ref":"/search/","title":"Search Results"}]